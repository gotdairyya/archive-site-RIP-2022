<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>gotdairyya blog</title>
    <description>Thoughts and musings about data vis, ethics, and everything else by derya akbaba.</description>
    <link>http://localhost:4000</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>Cooking Up Knowledge</title>
        <description>&lt;p&gt;I have always been fascinated with how we come to know things. Not just from a memorization perspective (in fact, I remember what I once memorized, but can no longer recall the content, which makes me question &lt;em&gt;the point&lt;/em&gt;), but rather from an embodied perspective. When do our muscles remember how to ride a bike? or our taste buds recommend the tiniest bit of lemon juice to balance the flavors? The inspiration for this post came when I was exchanging Turkish recipes&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; with a friend, who was in turn exchanging Bangladeshi recipes. In addition to the recipe, we both included long explanations of what needed to be done so that the recipe would turn out like the way our grand-/mothers made the recipe (aka the right way). The ancesteral, cultural, and gustatory knowledge was embedded in the practice of cooking, eating and family; and yet, mostly missing from the black and white text of the recipes. We attempted to fill in this gap with more text, but it is unclear either of us will make the dishes authentically. This exchange reminded me about two academic concepts that I have been fascinated with as of late: tacit knowledge in science and pedagogical content knowledge in education. Both relate to how &lt;em&gt;verbs&lt;/em&gt; are done and the quality to which they are done. Below I include a BRIEF overview of each. I am still new to both fields/concepts, and so I would love further recommendations and to engage in more discussion (just tweet &lt;a href=&quot;https://twitter.com/gotdairyya&quot;&gt;@gotdairyya&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;In the social studies of science, tacit knowledge has been studied as the magic sauce for getting science done. In H.M. Collins’ Paper,&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; he discusses how tacit knowledge plays an important role in measuring the quality of sapphire. &lt;em&gt;A brief aside, the shortening of the quality of sapphire is the q of sapphire and that always conjures up for me images of Quailman.&lt;/em&gt; &lt;img src=&quot;https://media.giphy.com/media/l4EpkQcjHPsr9tTP2/giphy.gif&quot; alt=&quot;GIF of Quailman an early 2000s cartoon character&quot; class=&quot;scale-50-center&quot; /&gt; It is a super fascinating read discussing how the lingering dynamics of Cold War politics were overcome over by two labs spending time together, learning the way experiments were conducted through engaging in observation and learning, ultimately united by ‘the language of science.’ If this isn’t a thriller, I don’t know what is. To read more, I would recommend the works of Susan Leigh Star and Geoffrey Bowker. &lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;In education research, I’ve seen tacit knowledge show up as Pedagogical Content Knowledge (PCK). PCK “encapsulates all that the teacher has to know in order to teach a subject effectively”. &lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; Effectively could mean how to get the students excited about the topic, how to teach so that students can recall concepts in later and differing concepts, what metaphors tend to work and which ones don’t, teaching inclusive design &lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;…There is so much to the act of teaching that extends beyond the content material.&lt;/p&gt;

&lt;p&gt;What I have written about is just scratching the surface of the different ways of knowing. I wanted to jot down these inital thoughts, fully recognizing that they are incomplete. From cooking, to social studies of science, to education research knowing about knowing + knowing about doing impact the types of things that can be done and the extent to which they can be done well. How often are we engaging in discussions at this meta-level?&lt;/p&gt;

&lt;p&gt;What fascinates me is how can we communicate all the stuff we know about stuff? Are there ways to hint at how little the instructions we write or the data we display represent the full and embodied nature of our knowing? How can technological systems support/obstruct the transfer of knowledge?&lt;/p&gt;

&lt;h3 id=&quot;acknowledgements&quot;&gt;Acknowledgements&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;I need to thank Os Keyes for bringing all of the tacit knowledge papers to my attention and Eliane Wiese for the papers on PCKs.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h3&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;&lt;strong&gt;[1]&lt;/strong&gt; Here is my recipe for a &lt;a href=&quot;https://docs.google.com/document/d/1YSAiKWlD3YjaoIJhVheg7uDbISUI9edG9rAxSuDwbP0/edit?usp=sharing&quot;&gt;vegan spinach borek&lt;/a&gt;. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;&lt;strong&gt;[2]&lt;/strong&gt; Collins, H. M. (2001). Tacit knowledge, trust and the Q of Sapphire. Social Studies of Science, 31(1), 71–85. https://doi.org/10.1177/030631201031001004 &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;&lt;strong&gt;[3]&lt;/strong&gt; Bowker, G. C., &amp;amp; Star, S. L. (1999). Sorting Things Out: Classification and Its Consequences. Massachusetts Institute of Technology. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;&lt;strong&gt;[4]&lt;/strong&gt; Brandes, O., &amp;amp; Armoni, M. (2019). Using action research to distill research-based segments of pedagogical content knowledge of K-12 computer science teachers. Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE, 485–491. https://doi.org/10.1145/3304221.3319773 &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;&lt;strong&gt;[5]&lt;/strong&gt; Oleson, A., Mendez, C., Steine-Hanson, Z., Hilderbrand, C., Perdriau, C., Burnett, M., &amp;amp; Ko, A. J. (2018). Pedagogical content knowledge for teaching inclusive design. ICER 2018 - Proceedings of the 2018 ACM Conference on International Computing Education Research, 69–77. https://doi.org/10.1145/3230977.3230998 &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 18 Apr 2021 00:00:00 -0600</pubDate>
        <link>http://localhost:4000//2021/04/18/cooking-knowledge.html</link>
        <guid isPermaLink="true">http://localhost:4000//2021/04/18/cooking-knowledge.html</guid>
      </item>
    
      <item>
        <title>What is Data Vis?</title>
        <description>&lt;p&gt;I often get asked – what is data vis? And often I answer with: “Well, it’s visualizing data. “ Incredibly helpful. I know.&lt;/p&gt;

&lt;p&gt;So, inspired by the very unhelpful patent images of the &lt;a href=&quot;https://noahveltman.com/internet-shape/&quot;&gt;shape of the internet&lt;/a&gt; found by Noah Veltman, I have found equally unhelpful images of data visualizations. Enjoy!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;strange white man from the 50s reads tablet&lt;/strong&gt;
&lt;a href=&quot;https://patents.google.com/patent/US20150220607A1/en?q=data+visualization&amp;amp;oq=data+visualization&quot;&gt;&lt;img src=&quot;/../assets/images/data-vis/contextual-vis.png&quot; alt=&quot;strange white man from the 50s&quot; class=&quot;responsive-image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;cute screens talk business to one another&lt;/strong&gt;
&lt;a href=&quot;https://patents.google.com/patent/US6995768B2/en?q=data+visualization&amp;amp;oq=data+visualization&quot;&gt;&lt;img src=&quot;/../assets/images/data-vis/business-vis.png&quot; alt=&quot;cute screens talk business to one another&quot; class=&quot;responsive-image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;vis can make you smile&lt;/strong&gt;
&lt;a href=&quot;https://patents.google.com/patent/US20170262425A1/en?q=data+visualization&amp;amp;oq=data+visualization&quot;&gt;&lt;img src=&quot;/../assets/images/data-vis/smiley-vis.png&quot; alt=&quot;vis can make you smile&quot; class=&quot;responsive-image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;aol man gets webcam&lt;/strong&gt;
&lt;a href=&quot;https://patents.google.com/patent/US20180189990A1/en?q=data+visualization&amp;amp;oq=data+visualization&amp;amp;page=1&quot;&gt;&lt;img src=&quot;/../assets/images/data-vis/aol-vis.png&quot; alt=&quot;aol man gets webcam&quot; class=&quot;responsive-image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 27 Nov 2020 00:00:00 -0700</pubDate>
        <link>http://localhost:4000//2020/11/27/what-is-datavis.html</link>
        <guid isPermaLink="true">http://localhost:4000//2020/11/27/what-is-datavis.html</guid>
      </item>
    
      <item>
        <title>Communicating Science Research</title>
        <description>&lt;p&gt;In early July I was a participant in the &lt;a href=&quot;https://comscicon.com/&quot;&gt;ComSciCon Flagship workshop&lt;/a&gt;. The 3-day workshop was conducted over Zoom and covered a variety of topics on how to communicate science research with non-scientists (we are all scientists but some of us choose to pursue it as a career). We discussed topics like empathy, complicating the narrative, heard from speakers on IDEA (Inclusion, Diversity, Equity, and Accessibility), and did a little improv to practice discomfort and thinking on our feet.&lt;/p&gt;

&lt;p&gt;As part of the conference, we were required to write a pop-science piece and then submit it to different journals. My piece was accepted by &lt;em&gt;Natural History&lt;/em&gt; and published in the September 2020 issue along with other ComSciCon participants.&lt;/p&gt;

&lt;p&gt;If there is one thing that I want to stress from this experience is that COMPUTER SCIENCE NEEDS MORE POP SCIENCE WRITERS!!!!! The Natural Sciences have it DOWN. But why let them have all the fun? Computers are in our daily lives, in our pockets, mediating the world we live in, and we (not the royal we, but the we-as-a-society we) would greatly benefit from a larger collective understanding about what computers are, what they do, and what research is being conducted about them!&lt;/p&gt;

&lt;p&gt;IF YOU ARE A COMPUTER SCIENTIST READING THIS, LET’S TALK!!!&lt;/p&gt;

&lt;p&gt;Anyway, it was a wonderful experience working with an editor (thank you for all of the comments and feedback!). I’ve listed resources on how to pitch to an editor below.&lt;/p&gt;

&lt;p&gt;You can read the piece by buying the magazine, or &lt;a href=&quot;/assets/images/nh/Sep20-NH-digital-edition.pdf&quot;&gt;here is my digital copy&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/nh/nh-cover.png&quot; alt=&quot;Image of the cover of the September 20 magazine. An adorable bat!&quot; class=&quot;scale-50-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How to Pitch to an Editor:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.theatlantic.com/business/archive/2013/08/how-not-to-pitch/279193/&quot;&gt;the Atlantic’s ‘How (Not) to Pitch’&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.theopennotebook.com/pitch-database/&quot;&gt;the Open Notebook’s Pitch Database&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/@annfriedman/how-and-where-to-pitch-your-writing-1c316fa37bda&quot;&gt;Medium article on how to make a pitch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 10 Sep 2020 00:00:00 -0600</pubDate>
        <link>http://localhost:4000//2020/09/10/comscicon.html</link>
        <guid isPermaLink="true">http://localhost:4000//2020/09/10/comscicon.html</guid>
      </item>
    
      <item>
        <title>Perspective</title>
        <description>&lt;p&gt;Came across this image on perspective: I’ve tried to figure out the illustrator + origin, but both Google and Pinterest failed me. (For all I know, the poster could be about something completely different, so if you have any leads on it please let me know!)&lt;/p&gt;

&lt;p&gt;Completely ignorant about the text, the colors and simplicity really struck me and I decided to play around a little with the background image. Yes, there is probably some deep meaning about the images I chose (like cows representing veganism and mountains representing the humbling power of nature), but ultimately the decisions were based on colors and composition.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/../assets/images/perspective/perspective-OG.png&quot; alt=&quot;original image on perspective displaying a pink tent 2-d image. There are three eyes that point out the different way this flattened three dimensional image can be interpreted: a square from one side, a triangle from the other, and two rectangles from the top.&quot; class=&quot;responsive-image&quot; /&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/../assets/images/perspective/perspective-01.png&quot; alt=&quot;my copy of the original because the original is a picture of an image.&quot; class=&quot;responsive-image&quot; /&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/../assets/images/perspective/perspective-02.png&quot; alt=&quot;my copy of the original with a cow in the background&quot; class=&quot;responsive-image&quot; /&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/../assets/images/perspective/perspective-03.png&quot; alt=&quot;my copy of the original with mountains and a beautiful Utah sunset in the background&quot; class=&quot;responsive-image&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
</description>
        <pubDate>Sat, 15 Aug 2020 00:00:00 -0600</pubDate>
        <link>http://localhost:4000//2020/08/15/perspective.html</link>
        <guid isPermaLink="true">http://localhost:4000//2020/08/15/perspective.html</guid>
      </item>
    
      <item>
        <title>Learning about Learning</title>
        <description>&lt;p&gt;It’s in many ways unbelievable to me that my first academic year of my PhD has come to an end. Not that I didn’t think I would make it, but more so I could not have even imagined the state of the world as it is now.&lt;/p&gt;

&lt;p&gt;The global pandemic has affected all of our lives sounds like an understatement. I take a few moments each day while I am slightly panicked or overwhelmed to pause and pretend how in a few years from now I will be looking back and recounting all the disruptions and things that I have learned in this moment.&lt;/p&gt;

&lt;p&gt;So what is it that I have learned?&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;(1) Don’t take anything for granted.&lt;/strong&gt;
This includes the little things like going to the grocery store after 8pm. And the big things, like cherishing the time you spend with friends and family.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;(2) Video calls are awesome.&lt;/strong&gt;
I think after this has passed I will continue to video call my friends and family. Video calling has helped me to pause and remain present during phone calls, when in the past I viewed calls as something to do while I was doing other things. I have come to love quick little updates from my family. Even the long video calls with my sister as we walk around our neighborhoods, East Bench and the Bronx, talking about nothing and everything at the same time.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;(3) Everything takes time.&lt;/strong&gt;
In some ways this year was harder than I imagined it would be. On and off I was plagued with imposter syndrome, worried that I was not doing research right. And I’m not sure when this happened, but towards the end of the semester something clicked for me – all of this is just going to take time and practice. In the same way that I have been learning how to enjoy the act of running, I am learning how to be a PhD student. There is definitely something meta here like “it’s not about the destination, it’s about the journey” and sure that totally applies, but no one mentioned the liberation you can feel when you begin to embrace that mindset.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;(4) Epistemology is not an onomatopoeia for a sneeze.&lt;/strong&gt; In fact, it is a super useful term to have in your toolbox and can help explain why you may disagree with someone else’s conclusions. I plan on writing an entry about this soon.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I don’t necessarily have a good conclusion for this entry because I am in a state of learning and processing but I have been accepted to &lt;a href=&quot;https://comscicon.com/&quot;&gt;ComSciCon&lt;/a&gt; and I hope that through the weekend virtual workshop I will have some new methods of communicating to experiment with!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Update Sept 9,2020: Read more about my experience with ComSciCon &lt;a href=&quot;/2020/09/10/comscicon.html&quot;&gt;here&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 01 May 2020 00:00:00 -0600</pubDate>
        <link>http://localhost:4000//2020/05/01/learning-about-learning.html</link>
        <guid isPermaLink="true">http://localhost:4000//2020/05/01/learning-about-learning.html</guid>
      </item>
    
      <item>
        <title>Abstract Abstracts</title>
        <description>&lt;p&gt;This is deep dive done by myself and my friend Cole Polychronis for our data mining class.&lt;/p&gt;

&lt;h3 id=&quot;motivation&quot;&gt;Motivation&lt;/h3&gt;
&lt;p&gt;Our project began with a desire to answer a question posed in the backlog of an online data visualization blog, &lt;a href=&quot;pudding.cool&quot;&gt;the Pudding&lt;/a&gt;: are the titles of scientific texts becoming harder to read? As two first-year graduate students who will be involved in the process of writing research papers and hope to reach large(r) audiences, we were immediately invested in this idea. While we both felt that we had anecdotal evidence that scientific papers were getting harder to read due to an increase in the use of jargon, acronyms, etc. we were also interested in expanding this question to not just investigate change in readability over time, but also to investigate whether different disciplines exhibited different types of change. Being able to identify if there are certain disciplines who “do readability” better would give us places to look for examples to emulate. As a means of managing the scope of our project, we elected to examine the readability of abstracts available on arXiv. In order to explore the readability of these scientific papers, we opted to use four of the most widely used readability metrics: Flesch-Kincaid Grade Level, Flesch Reading Ease, Automated Readability Index, and the Dale-Chall Readability. To build on these established readability measures, we explored using principal component analysis to reduce noise and discard redundancy amongst the various (similar) readability metrics, as well as removing domain specific keywords to improve the nuance of these readability metrics.&lt;/p&gt;

&lt;h3 id=&quot;data&quot;&gt;Data&lt;/h3&gt;
&lt;p&gt;Under the Open Archives Initiative, metadata and full text are available for download from arXiv. We began our search using the help page of ArXiv.org, but found that there was an already extracted subset of the data on &lt;a href=&quot;https://www.kaggle.com/tayorm/arxiv-papers-metadata/data#&quot;&gt;Kaggle&lt;/a&gt;. This subset on Kaggle is stored as tsvs according to either the category of research or the year of publication. In order to download from Kaggle, we had to create a Kaggle account and then download the zip file. The data is roughly 9GB and is comprised of the metadata for 1.5 million research papers, spanning roughly 25 different disciplines, collected between 1993 to 2019.&lt;/p&gt;

&lt;h3 id=&quot;key-idea&quot;&gt;Key Idea&lt;/h3&gt;
&lt;p&gt;Our initial intent for this project was to use several readability metrics that we discovered during our background research for this project in order to differentiate different disciplines. In particular, we identified the Flesch-Kincaid Grade Level, Flesch Reading Ease, Automated Readability Index, and the Dale-Chall Readability metrics to be significant metrics that are widely used across education and even employed by the United States Government to assess the readability of written documents. A key assumption that informed this research approach was our belief that we would see some pattern of decreased readability over time or variable readability across disciplines. However, as we began conducting the analysis for our intermediate report, we found that there were no distinctly readable disciplines and patterns that implied less or more readability. Additionally, across all four readability metrics that we used, we found that the results were not all that nuanced, indicating that the title and abstract together were consistently at a college or above reading level. The scores and their interpretations are summarized in Table 1. We’ve also Fig 1 to illustrate an example of our initial experiment.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Formula&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;PDW&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;ASL&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;ASW&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;CC&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;WC&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Interpretation&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Flesch KincaidGrade&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.39xASL + 11.8xASW - 15.59&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;x&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;x&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Corresponds directly to grade levels in the US. Anything above 12 is a college reading level.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Flesch Reading Ease&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;206.835 - (1.015 × ASL) - (84.6 × ASW)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;x&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;x&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Anything above 30 is difficult to read and intended for college students.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Automated Readability Index&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4.71xCC/WC + 0.5*WC/ASL - 21.43&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;x&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;x&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;x&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Corresponds to grade levels. Anything above 12 is a college reading level.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Dale-Chall&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.1579x(PDW) + 0.0496x(ASL) +3.6365&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;x&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;x&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Indirectly corresponds to grade levels. Anything above 9.0 is a college reading level.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;Table 1. This table represents the four major readability metrics and how to interpret the metric.PDW: Percentage of difficult words not on the Dale-Chall word list; ASL: Average sentence length; ASW: Average word length in syllables; CC: Character Count; WC: Word Count&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Given our lack of exciting results after experimenting for the intermediate report, we pivoted to exploring two complementary aspects of our readability criteria in the hopes of achieving a higher level of nuance and possibly identifying patterns that weren’t immediately obvious during our experimentation for the intermediate report.These complementary approaches were:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;A1. Using a combination of normalization and principal component analysis (PCA) could serve to reduce noise and discard redundancy between the multiple readability scores to identify a clearer pattern, either across time or discipline.&lt;/li&gt;
  &lt;li&gt;A2. Removing domain specific words could result in more conclusive and/or nuanced reading scores.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;experiments&quot;&gt;Experiments&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;A1. Normalization and PCA&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In order to conduct PCA, we first had to normalize our data to ensure that a difference in units was not the cause for explainability for a component. In order to normalize our data, we first had to determine if the scores for each one of our readability metrics were normally distributed. We recognized that in order to normalize our scores, we had to apply log transforms to both the Flesch-Kincaid Readability Measure and the Automated Readability Index, as these distributions had fairly long left and right tails, respectively.&lt;/p&gt;

&lt;p&gt;After transforming and normalizing these metrics, we applied PCA and kept the first two principal components in the hope of visualizing them. If there is a difference in readability of scientific papers, either across discipline or time, we would hope to see some clustering loosely along the diagonal, with a position further up the diagonal indicating that cluster is more difficult to read according to our readability metrics. The results of applying PCA are discussed in the results section below.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A2. Removing Domain Specific Words&lt;/strong&gt;
Inspired by research in medical literature readability, we decided to explore the effect that removing domain-specific words from abstracts would have on readability scores. In medical information retrieval literature, methods of categorizing the difficulty of word comprehension (or inversely, the domain knowledge necessary to understand a word) are aided by referencing the Medical Subject Headings, the U.S. National Library of Medicine’s hierarchical term thesaurus (see: Xin Yan, Dawei Song, and Xue Li. 2006. Concept-based document readability in domain specific information retrieval.).&lt;/p&gt;

&lt;p&gt;Given that we did not have access to a controlled thesaurus to indicate the difficulty of domain-specific words, we had to construct our own frequent domain word list. We created two word vectors of equal length: one of domain-specific words V_D and one of random words V_R. The domain-specific V_D was created using the word frequency found across abstracts within a discipline over the entire time period that the discipline spanned.&lt;/p&gt;

&lt;p&gt;To construct the vectors, the abstracts were first stripped of stop-words. Next, we found the word frequency of all the words that occurred within a discipline over the full period of time available on arXiv. V_D was constructed with the top n words, and V_R was constructed of n random words from the same list.&lt;/p&gt;

&lt;p&gt;We tested typically used n = 100 when running the experiments after testing values of n that were larger and smaller than 100. We found that removing too few words did not capture the breadth of domain jargon present in abstracts and removing too many words would result in shorter abstracts, affecting the readability scores.&lt;/p&gt;

&lt;p&gt;By taking the top n words that occurred in a discipline over time and removing them from the abstracts we hoped the resulting readability scores would be representative of the true readability sans domain-specific knowledge. Additionally, the exclusion of domain knowledge from abstracts would enable us to compare readability scores across domains in order to understand a more general trend of readability in research papers found in ArXiv.&lt;/p&gt;

&lt;p&gt;Finally, we tested the impact of removing n random words to check whether the change in readability scores was a result of removing domain specific words or making the abstracts shorter in length.&lt;/p&gt;

&lt;h3 id=&quot;results&quot;&gt;Results&lt;/h3&gt;

&lt;p&gt;The visualization of our data projected onto the two most important principal components yielded by PCA is shown below. If there is a difference in readability of scientific papers, either across discipline or time, we would hope to see some clustering loosely along the diagonal, with a position further up the diagonal indicating that cluster is more difficult to read according to our readability metrics.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt; &lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;img src=&quot;/../assets/images/abstractabstracts/domainPCA.png&quot; alt=&quot;PCA by domain, it's a big ole blob of nothing interesting&quot; class=&quot;responsive-image&quot; /&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;img src=&quot;/../assets/images/abstractabstracts/yearPCA.png&quot; alt=&quot;PCA by year, like the PCA by domain, it's a big ole blob of nothing interesting&quot; class=&quot;responsive-image&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Before discussing the details of either coloration of the projected data above, one of the key observations that we can make from either chart is that there is a distinct lack of clustering! Rather, there is one large ‘blob’ of data, which we can loosely interpret as being centered at an average level of scientific paper readability, with a whispy tail along the diagonal, indicating papers that are not as easily readable.&lt;/p&gt;

&lt;p&gt;Looking at the projected data by domain is relatively uninformative. We can see that the domain of biology is most tightly packed around the center, with math forming a looser packing, which we can interpret to mean that there is more variability in the readability of papers in math as compared to biology. The rest of the domain are disperse in a way that means that we can’t glean much about these domains comparatively. We notice that the less readable papers are comprised of physics and computer science papers. However, there is not much weight to this tail along the diagonal, so it is hard to say much about this.&lt;/p&gt;

&lt;p&gt;A bit more interesting of a distinction can be made when we look at the projected data by year of publication. While we still only see a large blob centered around mean readability, we can see that papers published before roughly 1990-2000 are more tightly packed than papers published after 2000. This means that overtime, the readability of scientific papers has not necessarily increased or decreased, but has become much more variable; papers span a much wider range on the readability spectrum than they did 20 years ago. Informally, papers haven’t gotten easier to read or harder to read since the 90’s, the readability of papers has become a more extreme crapshoot.&lt;/p&gt;

&lt;p&gt;Removing domain specific words yielded two somewhat surprising results.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Removing domain specific words from abstracts did not affect the readability scores.&lt;/li&gt;
  &lt;li&gt;Removing random words had the same effect as removing domain specific words.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;On further consideration, these results are not too surprising because the readability scores (aside from the Dale-Chall) calculate readability using non-semantic metrics such as sentence length, character count and word count. By removing n words, regardless of whether it was domain specific or random, we affected both the character count and the word count.&lt;/p&gt;

&lt;h3 id=&quot;discussion&quot;&gt;Discussion&lt;/h3&gt;
&lt;p&gt;Ultimately, our experimentation with applying readability metrics to scientific papers defy our expectations and anecdotal examples: readability does not seem to have increased or decreased over the last 30 years and further, there doesn’t necessarily seem to be one discipline that “does” readability better than others. Instead, we found that readability of scientific papers has become more varied over time. This perhaps makes sense, given the proliferation of venues for papers and the volume and variety of research being conducted now versus 30 years ago.&lt;/p&gt;

&lt;p&gt;However, we also feel that our experimentation has demonstrated that to a certain extent, existing readability metrics lack the nuance and complexity to identify readability of research papers. As discussed above, all of these reading metrics identified that our papers were above a college reading level (which is to be expected), with little relevance existing at the varying levels of scores above a college reading level. Our experimentation with removing words from text shows that these metrics lack a means of identifying semantic importance of certain text features such as stop words. This experimentation has lead us to conclude that readability metrics need more semantic awareness in order to compare and understand readability of scientific documents.&lt;/p&gt;

&lt;p&gt;Sooo you could say we found nothing or someone’s PhD thesis…
&lt;img src=&quot;/../assets/images/daria-shrug.gif&quot; alt=&quot;daria from the animated tv show shrugging. she is my alter-ego and i never watched the show till 2020&quot; class=&quot;scale-50-center&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 23 Apr 2020 00:00:00 -0600</pubDate>
        <link>http://localhost:4000//2020/04/23/abstract-abstracts.html</link>
        <guid isPermaLink="true">http://localhost:4000//2020/04/23/abstract-abstracts.html</guid>
      </item>
    
      <item>
        <title>Trustworthiness in Qualitative Research</title>
        <description>&lt;p&gt;This year I am taking a class taught by my advisor Miriah Meyer on ontologies, epistemologies, and research paradigms. I will have to write another post on what those words mean at some point, but for now I want to focus on an interesting conversation we have been having: how can researchers communicate rigor if their work is qualitative.&lt;/p&gt;

&lt;h3 id=&quot;learning-to-trust-a-positivist-perspective&quot;&gt;Learning to Trust: a Positivist Perspective&lt;/h3&gt;

&lt;p&gt;Positivism is a research paradigm often associated with the natural sciences. In the world of positivism, there are objective and generalizable truths that can be measured. Within positivism, research results are judged according to the following criteria:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Internal Validity:&lt;/strong&gt; how certain are you that the independent variable has effected the dependent variable?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;External Validity:&lt;/strong&gt; how representative is the sample population (and by extension your results) of the general population?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reproducibility &amp;amp; Reliability:&lt;/strong&gt; how likely are the results to show up again in another experiment? how well can another researcher run your experiment?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Objectivity:&lt;/strong&gt; are the measurements value free?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These criteria are often associated with quantitative studies, but they become problematic when there is no &lt;em&gt;one&lt;/em&gt; answer to your research, no &lt;em&gt;one&lt;/em&gt; singular truth, and when the socio-, historical-, political- contexts of the experiment can greatly affect your results.&lt;/p&gt;

&lt;p&gt;Enter, Lincoln, Guba, and interpretivism.&lt;/p&gt;

&lt;h3 id=&quot;establishing-trustworthiness&quot;&gt;Establishing Trustworthiness&lt;/h3&gt;
&lt;p&gt;The following section is my take on organizing the work presented in &lt;a href=&quot;https://ethnographyworkshop.files.wordpress.com/2014/11/lincoln-guba-1985-establishing-trustworthiness-naturalistic-inquiry.pdf&quot;&gt;Establishing Trustworthiness&lt;/a&gt;. Written in 1985, this document from my understanding is a seminal piece in interpretivist research methods. Lincoln and Guba set out to both make a case for interpretivism (the research paradigm that multiple realities exist and it is the role of the researcher to interpret it) and provide practical methods for establishing trust and rigor in qualitative research.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Credibility:&lt;/strong&gt; How congruent are the findings with reality? &lt;br /&gt;
&lt;em&gt;Positivist Analogy: internal validity&lt;/em&gt;&lt;/p&gt;
&lt;details&gt;&lt;summary&gt;Methods&lt;/summary&gt;
&lt;p&gt;
&lt;ul&gt;
&lt;li&gt;Adopting appropriate research methods&lt;/li&gt;
&lt;li&gt;Establishing a rapport with the participants through long-term engagement&lt;/li&gt;
&lt;li&gt;Expanding participants to include randomly selected individuals&lt;/li&gt;
&lt;li&gt;Analyzing edge cases and how they fit or don't fit within your research conclusions&lt;/li&gt;
&lt;li&gt;Debriefing with peers&lt;/li&gt;
&lt;li&gt;Checking your conclusions with the research participants&lt;/li&gt;
&lt;li&gt;Triangulating results using different sources of deta, methods of collection, and interpretations&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;strong&gt;Transferability:&lt;/strong&gt; To what extent are the findings applicable to other contexts? It is important to note that the onus of transferring research results falls on the consumer of the research.&lt;br /&gt;
&lt;em&gt;Positivist Analogy: external validity&lt;/em&gt;&lt;/p&gt;
&lt;details&gt;&lt;summary&gt;Methods&lt;/summary&gt;
&lt;p&gt;
&lt;ul&gt;
&lt;li&gt;Using thick descriptions to communicate the context&lt;/li&gt;
&lt;li&gt;Including information regarding the type of data used (or omitted), length of study, participants, and other relevant details&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;strong&gt;Dependability:&lt;/strong&gt; Have you provided enough information so that other researchers could repeat the work? &lt;br /&gt;
&lt;em&gt;Positivist Analogy: reproducibility &amp;amp; reliability&lt;/em&gt;&lt;/p&gt;
&lt;details&gt;&lt;summary&gt;Methods&lt;/summary&gt;
&lt;p&gt;
&lt;ul&gt;
&lt;li&gt;Explaining the research design in rich details&lt;/li&gt;
&lt;li&gt;Enumerating the methods of gathering data&lt;/li&gt;
&lt;li&gt;Reflexive journaling&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;strong&gt;Confirmability:&lt;/strong&gt; Does your data support your interpretations? &lt;br /&gt;
&lt;em&gt;Positivist Analogy: objectivity&lt;/em&gt;&lt;/p&gt;
&lt;details&gt;&lt;summary&gt;Methods&lt;/summary&gt;
&lt;p&gt;
&lt;ul&gt;
&lt;li&gt;Including an audit trail for review&lt;/li&gt;
&lt;li&gt;Maintaining transparency about your methods, research design, and conclusion development&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;As you can see, even with these methods, it is hard to grapple with what makes research trustworthy? Especially in a non-positivist paradigm we are relying on individual interpretations, where there will not be one single correct answer. For me, this is the beauty of science that is often overlooked: as humans we have the innate ability to observe the world around us and communicate our observations with others to build collective knowledge, knowing that we may not be 100% correct all the time.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Further Reading:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://eric.ed.gov/?id=EJ792970&quot;&gt;More in depth methods summarized from the Lincoln and Guba paper&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 22 Jan 2020 00:00:00 -0700</pubDate>
        <link>http://localhost:4000//2020/01/22/trustworthiness.html</link>
        <guid isPermaLink="true">http://localhost:4000//2020/01/22/trustworthiness.html</guid>
      </item>
    
      <item>
        <title>Data Portraits</title>
        <description>&lt;p&gt;I started writing this blog post a couple times, not entirely sure what was the appropriate introduction to a topic I am deeply fascinated with, so here are a few intros that didn’t make the cut…&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Instead of working on my final project for data vis, I am writing about it…&lt;/em&gt;&lt;/p&gt;

  &lt;p&gt;&lt;em&gt;Really if you think about it, everything is a data portrait…&lt;/em&gt;&lt;/p&gt;

  &lt;p&gt;&lt;em&gt;If everything is a data portrait, then what is a data portrait?&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As you can see, not the best intros. What I would like to do instead, is talk about some inspiration I’ve had over the years regarding data portraits, and then show you what I have created for a class project.&lt;/p&gt;

&lt;h3 id=&quot;inspiration-comes-in-many-forms&quot;&gt;Inspiration Comes in Many Forms&lt;/h3&gt;

&lt;p&gt;One form is Georgia Lupi. Lupi a partner at Pentagram studios and a long time advocate for &lt;em&gt;data humanism&lt;/em&gt;, constantly likes to remind us that data is never the point, the humans who created it are. I hope to draw on this concept throughout my PhD. Often, data is assumed to be objective, immutable, authoritative, but ultimately it is another human creation, prone to errors and up to interpretation.
&lt;a href=&quot;https://www.ted.com/talks/giorgia_lupi_how_we_can_find_ourselves_in_data?language=en#t-258497&quot;&gt;For more on Lupi, you can listen to her TED Talk&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/../assets/images/data-portraits/georgia-lupi-portraits.jpg&quot; alt=&quot;example of data portraits from Georgia Lupi&quot; class=&quot;responsive-image&quot; /&gt;&lt;/p&gt;
&lt;figcaption&gt;
  &lt;p&gt;An example of data portraits courtesy of ideas.ted.com.&lt;/p&gt;
&lt;/figcaption&gt;

&lt;p&gt;Another inspiration comes from nature and ways in which data can be interpreted as traces and proof of life. In Dietmar Offenhuber’s paper &lt;a href=&quot;https://arxiv.org/abs/1907.05454&quot;&gt;Data by Proxy&lt;/a&gt;, he discusses the concept of discovering and revealing the traces of natural processes and abstracting them into a data and data visualizations. Although it might sound slightly abstract, I think it is something we do rather intuitively…&lt;/p&gt;

&lt;p&gt;We can see patterns in how we step by looking at the uneven wear on the soles of our shoes.
The rings of trees show us the age of the tree.
White and grey hairs indicate age.&lt;/p&gt;

&lt;p&gt;If we want, we can take all these observations and abstract them into numbers, but maybe I will talk about that later.&lt;/p&gt;

&lt;p&gt;My final, but not final, inspiration comes from an Italian data visualization designer, Federica Fragapane, who makes the most out-of-this-world data portraits. I’ll let the examples below speak for themselves.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/../assets/images/data-portraits/federica-fragapane-carbon-dioxide.jpg&quot; alt=&quot;example of data portraits from Federica Fragapane&quot; class=&quot;responsive-image&quot; /&gt;
&lt;img src=&quot;/../assets/images/data-portraits/federica-fragapane-violent-cities.jpg&quot; alt=&quot;example of data portraits from Federica Fragapane&quot; class=&quot;responsive-image&quot; /&gt;&lt;/p&gt;
&lt;figcaption&gt;
  &lt;p&gt;You can find more of her work on her &lt;a href=&quot;https://www.behance.net/FedericaFragapane&quot;&gt;Behance site&lt;/a&gt;&lt;/p&gt;
&lt;/figcaption&gt;

&lt;h3 id=&quot;my-take-of-data-portraits&quot;&gt;My take of Data Portraits&lt;/h3&gt;
&lt;p&gt;For my group project, we are visualizing data about museum artifacts. In spirit of the artwork, I wanted to create art that would represent the museum and it’s collection.&lt;/p&gt;

&lt;p&gt;I began by looking at different Abstract Expressionism art, looking specifically for the use of bold colors and geometric shapes. Once I selected an artist for inspiration, I created a rough mockup using pen + paper of what the portrait could look like.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/../assets/images/data-portraits/portrait-mockup.png&quot; alt=&quot;data portrait mock-up on post-it note&quot; class=&quot;scale-50-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Pleased with the rough sketch, I used Adobe Illustrator for cleaner mock-ups. After implementing the design in code using fake (but representative) data, I altered the design slightly to both make the coding easier and incorporate a more organic element into the design.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/../assets/images/data-portraits/data-portrait-mockup-01.png&quot; alt=&quot;data portrait mock-up from illustrator&quot; class=&quot;responsive-image&quot; /&gt;
&lt;img src=&quot;/../assets/images/data-portraits/data-portrait-mockup-02.png&quot; alt=&quot;data portrait mock-up from illustrator&quot; class=&quot;responsive-image&quot; /&gt;
&lt;img src=&quot;/../assets/images/data-portraits/data-portrait-mockup-03.png&quot; alt=&quot;data portrait mock-up from illustrator&quot; class=&quot;responsive-image&quot; /&gt;
&lt;img src=&quot;/../assets/images/data-portraits/data-portrait-mockup-04.png&quot; alt=&quot;data portrait mock-up from illustrator&quot; class=&quot;responsive-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And here is an interactive version of the portraits: &lt;br /&gt;
Hover to see the museum each portrait represents.&lt;/p&gt;
&lt;html lang=&quot;en&quot;&gt;

&lt;head&gt;
  &lt;meta charset=&quot;utf-8&quot; /&gt;
  &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot; /&gt;

  &lt;script src=&quot;https://d3js.org/d3.v5.js&quot;&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;style&gt;
  .porButton {
    fill: rgba(255, 225, 225, 0);
  }

  .porButton.not-selected {
    fill: rgba(255, 225, 225, .5);
  }

  .porButton.selected {
    fill: rgba(255, 225, 225, 0);
  }

  .porButton:hover {
    fill: rgba(255, 225, 225, 0)
  }

  .porButton:not(hover) {
    fill: rgba(255, 225, 225, .5);
  }

  div.tooltip {
    /* FOR PORTRAIT TOOLTIP */
    position: absolute;
    text-align: center;
    width: 60px;
    height: 28px;
    padding: 2px;
    font: 12px sans-serif;
    background: lightsteelblue;
    border: 0px;
    border-radius: 8px;
    pointer-events: none;
  }
&lt;/style&gt;

&lt;body&gt;
  &lt;script&gt;
    let data = [{
        museum: &quot;canada-science-and-technology-museums&quot;,
        years: 26970,
        countries: 59,
        artifacts: 26970,
        yearWidths: [0, 0, 0, 0, 1]
      },
      {
        museum: &quot;cleveland-museum-of-art&quot;,
        years: 43957,
        countries: 84,
        artifacts: 43957,
        yearWidths: [0.0027754396341879563, 0.033669267693427665, 0.03269103896990241, 0.10021157039834383, 0.8306526833041381]
      },
      {
        museum: &quot;cooper-hewitt-smithsonian-design-museum&quot;,
        years: 20117,
        countries: 69,
        artifacts: 20117,
        yearWidths: [0, 0.4706467167072625, 0.00004970920117313715, 0.0005965104140776457, 0.5287070636774867]
      },
      {
        museum: &quot;metropolitan-museum-of-art&quot;,
        years: 67113,
        countries: 160,
        artifacts: 67113,
        yearWidths: [0.4162531849269143, 0.05827484988005305, 0.09899721365458257, 0.08943125772950099, 0.3370434938089491]
      },
      {
        museum: &quot;museum-of-modern-art&quot;,
        years: 70716,
        countries: 102,
        artifacts: 70716,
        yearWidths: [0, 0, 0, 0, 1]
      },
      {
        museum: &quot;penn-museum&quot;,
        years: 43518,
        countries: 103,
        artifacts: 43518,
        yearWidths: [0.542005606875316, 0.15290224734592583, 0.04051197205753941, 0.03531871869111632, 0.22926145503010248]
      },
      {
        museum: &quot;minneapolis-institute-of-art&quot;,
        years: 9906,
        countries: 20,
        artifacts: 9906,
        yearWidths: [0, 0, 0, 0.0031294165152432867, 0.9968705834847568]
      },
      {
        museum: &quot;global&quot;,
        years: 2,
        countries: 1,
        artifacts: 2,
        yearWidths: [0, 1, 0, 0, 0]
      }
    ]


    let artifactsNum = []
    for (let museum of data) {
      artifactsNum.push(museum.artifacts)
    }

    let i = 0;
    let svg = d3.select(&quot;div.article-entry&quot;).append(&quot;svg&quot;).attr(&quot;width&quot;, 500).attr(&quot;height&quot;, 600)
    for (let museum of data) {
      drawPortrait(museum, i, svg)
      i++
    }


    function drawPortrait(museum, i, svg) {
      // let svg = d3.select(&quot;div.article-entry&quot;).append(&quot;svg&quot;).attr(&quot;width&quot;, 500).attr(&quot;height&quot;, 600)
      svg = svg.append(&quot;g&quot;)

      let colors = [&quot;#b5a5e3&quot;, &quot;#b1af00&quot;, &quot;#ff5b1a&quot;, &quot;#e2a333&quot;, &quot;#5b7769&quot;]

      let artifactScale = d3.scaleOrdinal()
        .domain([d3.min(artifactsNum), d3.max(artifactsNum)])
        .range([1, 5])

      let frameWidth = 238 * .3
      let frameHeight = 360 * .3
      let rectWidth = [0]

      let portraitColors = svg
        .selectAll(&quot;rect&quot;)
        .data(museum.yearWidths)
        .join(&quot;rect&quot;)
        .attr(&quot;height&quot;, frameHeight)
        .attr(&quot;width&quot;, (d, i) =&gt; {
          rectWidth.push((d * frameWidth) + rectWidth[i]);
          return d * frameWidth
        })
        .style(&quot;fill&quot;, (d, i) =&gt; colors[i])
        .attr(&quot;x&quot;, (d, i) =&gt; rectWidth[i])
        .attr(&quot;transform&quot;, &quot;translate(7,5)&quot;)

      let lineWidth = artifactScale(museum.artifacts)

      let artifactLine = svg
        .append(&quot;line&quot;)
        .attr(&quot;x1&quot;, frameWidth / 2)
        .attr(&quot;y1&quot;, frameHeight)
        .attr(&quot;x2&quot;, frameWidth)
        .attr(&quot;y2&quot;, frameHeight - (frameWidth / 2))
        .style(&quot;stroke&quot;, &quot;black&quot;)
        .style(&quot;stroke-width&quot;, lineWidth)
        .attr(&quot;transform&quot;, &quot;translate(5,5)&quot;)

      let countries = museum.countries
      countries = countries / 6;
      countries = Math.round(countries)
      let countryArray = []

      for (let i = 0; i &lt; countries; i++) {
        countryArray.push(i)
      }

      let countryDots = svg
        .selectAll(&quot;circle&quot;)
        .data(countryArray)
        .join(&quot;circle&quot;)

      let j = 0;
      let k = 3
      countryDots
        .attr(&quot;r&quot;, 5)
        .attr(&quot;cx&quot;, function(d, i) {
          if (i &lt; 10) {
            if (i % 2 === 0) {
              return (i * 10) + 10
            } else {
              return (i * 10) + 20
            }
          } else if (i &gt;= 10 &amp;&amp; i &lt; 20) {
            if (i % 2 === 0) {
              j = j + 1
              return (j * 10) + 10
            } else {
              j = j + 1
              return (j * 10) + 20
            }
          } else {
            if (i % 2 === 0) {
              k = k + 1
              return (k * 10) + 10
            } else {
              k = k + 1
              return (k * 10)
            }
          }
        })
        .attr(&quot;cy&quot;, function(d, i) {
          if (i &lt; 10) {
            return (i * 10) + 10
          } else if (i &gt;= 10 &amp;&amp; i &lt; 20) {
            return ((i - 10) * 10) + 10
          } else {
            return ((i - 20) * 10 - 10)
          }
        })
        .attr(&quot;transform&quot;, &quot;translate(7,20) scale(.5)&quot;)

      let ticker = i
      svg
        .attr(&quot;transform&quot;, function() {
          if (ticker &lt; 4) {
            if (ticker === 0) {
              return `translate(0,${frameHeight*.2})`
            } else {
              return `translate(0,${ticker*1.2*frameHeight+(frameHeight*.2)})`
            }
          } else {
            ticker = ticker - 4
            if (ticker === 0) {
              return `translate(${frameWidth*1.2},${frameHeight*.2})`
            } else {
              return `translate(${frameWidth*1.2},${ticker*1.2*frameHeight+(frameHeight*.2)})`
            }
          }
        })
        .attr(&quot;margin&quot;, 20)

      let frame = svg.append(&quot;rect&quot;)
        .attr(&quot;width&quot;, frameWidth)
        .attr(&quot;border&quot;, 20)
        .attr(&quot;height&quot;, frameHeight)
        .style(&quot;stroke&quot;, &quot;black&quot;)
        .style(&quot;stroke-width&quot;, 5)
        // .style(&quot;fill&quot;, &quot;none&quot;)
        // .style(&quot;fill&quot;, &quot;rgba(35, 29, 150, 0)&quot;)
        .attr(&quot;transform&quot;, &quot;translate(5,5)&quot;)
        .attr(&quot;id&quot;, museum.museum)
        .attr(&quot;class&quot;, &quot;porButton&quot;)
      // .attr(&quot;data-tabindex&quot;, 0)


      frame.on(&quot;mouseover&quot;, function(d) {
        let title = museum.museum
        // d3.selectAll(&quot;.porButton&quot;).attr(&quot;opacity&quot;, title === that.vizCoord.activeMuseum ? 1 : .2)
        title === &quot;metropolitan-museum-of-art&quot; ? title = &quot;The Met&quot; : title === &quot;minneapolis-institute-of-art&quot; ? title = &quot;Mia&quot; : title === &quot;cooper-hewitt-smithsonian-design-museum&quot; ? title = &quot;Cooper Hewitt&quot; : title === &quot;penn-museum&quot; ? title =
          &quot;Penn Museum&quot; : title === &quot;cleveland-museum-of-art&quot; ? title = &quot;Cleveland Museum of Art&quot; : title === &quot;museum-of-modern-art&quot; ? title = &quot;MoMa&quot; : title === &quot;global&quot; ? title = &quot;All Museums&quot; : title =
          &quot;Canada Science and Technology Museum&quot;
        d3.select(this).append('svg:title')
          .text(title)
      });


    } //end drawPortraits

    // make responsive
    // resizeSVG(svg) {
    //   let that = this
    //   // get container + svg aspect ratio
    //   let container = d3.select(svg.node().parentNode),
    //     width = parseInt(svg.style(&quot;width&quot;)),
    //     height = parseInt(svg.style(&quot;height&quot;)),
    //     aspect = width / height;
    //
    //   svg.attr(&quot;viewBox&quot;, &quot;0 0 &quot; + width + &quot; &quot; + height)
    //     .attr(&quot;perserveAspectRatio&quot;, &quot;xMinYMid&quot;)
    //     .call(resize);
    //
    //   d3.select(window).on(&quot;resize.&quot; + container.attr(&quot;id&quot;), resize);
    //
    //   // get width of container and resize svg to fit it
    //   function resize() {
    //     let targetWidth = parseInt(container.style(&quot;width&quot;));
    //     svg.attr(&quot;width&quot;, targetWidth);
    //     svg.attr(&quot;height&quot;, Math.round(targetWidth / aspect));
    //   }
    // }
  &lt;/script&gt;
&lt;/body&gt;

&lt;/html&gt;
</description>
        <pubDate>Thu, 21 Nov 2019 00:00:00 -0700</pubDate>
        <link>http://localhost:4000//2019/11/21/data-portraits.html</link>
        <guid isPermaLink="true">http://localhost:4000//2019/11/21/data-portraits.html</guid>
      </item>
    
      <item>
        <title>Visualizing Uncertainty</title>
        <description>&lt;p&gt;Since starting my PhD I have read A LOT. Now, you, like my wise friend Treasure may be saying, “Well duh derya, didn’t you know that that’s what a PhD is?!” Well. My wise friends, I did not.&lt;/p&gt;

&lt;p&gt;So like I was saying, I’ve been reading a lot and I’ve decided to use this blog as a way of reflecting on articles that I’ve found interesting/still have opinions on/want to go further than a one hour group discussion. To my peers’ credit though, discussion is so critical, and without them I don’t think I would be nearly as informed.&lt;/p&gt;

&lt;h3 id=&quot;why-authors-dont-visualize-uncertainty&quot;&gt;Why Authors Don’t Visualize Uncertainty&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Written by Jessica Hullman (&lt;a href=&quot;http://users.eecs.northwestern.edu/~jhullman/Value_of_Uncertainty_Vis_CR.pdf&quot;&gt;full paper here&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In this paper, Hullman investigates why visualization authors don’t visualize uncertainty when they know that it exists. The title of the paper is pretty self-explanatory, but there are some interesting discussion topics that I will dive deeper into.&lt;/p&gt;

&lt;p&gt;Let’s start with defining uncertainty in the visualization space.
Uncertainty can enter the visualization pipeline at many steps of the process, resulting in different types of uncertainty. Below is a simple pipeline illustrating potential areas where uncertainty may be introduced.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;As a side note, these are the same spaces where there are potential biases filtering in. Read &lt;a href=&quot;http://www.kanarinka.com/wp-content/uploads/2015/07/IEEE_Feminist_Data_Visualization.pdf&quot;&gt;Feminist Data Visualization&lt;/a&gt; for a more nuanced discussion.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/../assets/images/uncertainty/visualization-process.png&quot; alt=&quot;a table displaying the four simplified phases of visualization&quot; class=&quot;responsive-image&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;visualizing-uncertainty-is-hard&quot;&gt;Visualizing uncertainty is hard!&lt;/h4&gt;
&lt;p&gt;As you can see in the figure above, there are different types of uncertainty that could or could not be visualized. And based on what I have gathered through informal questioning (no formal review of the literature yet), there are no standard methods for visualizing uncertainty because really the choices you would have to make as a visualization designer all depend on the context.&lt;/p&gt;

&lt;p&gt;So what do the 90 visualization experts surveyed by Hullman do when confronted with uncertainty?&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Method&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Vis Example&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;%&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Interval Representation&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;img src=&quot;/../assets/images/uncertainty/confidence-intervals.png&quot; alt=&quot;confidence interval example&quot; class=&quot;table-image&quot; /&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;76&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Visual Variables&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;img src=&quot;/../assets/images/uncertainty/visual-variables.png&quot; alt=&quot;visual variables example&quot; class=&quot;table-image&quot; /&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;75&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Density Plot/Histogram&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;img src=&quot;/../assets/images/uncertainty/histogram.png&quot; alt=&quot;histogram example&quot; class=&quot;table-image&quot; /&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;54&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Text&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;margin of error is 5%&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;51&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Given that there are &lt;em&gt;some&lt;/em&gt; methods of visualizing uncertainty, the interesting aspect of Hullman’s results involve asking &lt;em&gt;why&lt;/em&gt; authors are not visualizing uncertainty. For that, yes, I made another table.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Reason&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;%&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Not to overwhelm viewers&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;62&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Not having access to uncertainty information&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;47&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Not knowing how to calculate uncertainty&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;26&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Not wanting to raise doubts in the data&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;17&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Using the results of her survey, Hullman proposes both a rhetorical model of uncertainty omission and formal theory of visualization-based inference, neither of which I will discuss here. Instead, I’d like to relate the reasons of uncertainty omission to the visualization process and task definition. My ideas of process are informed by personal experience and drawn from the &lt;a href=&quot;https://www.cs.ubc.ca/labs/imager/tr/2009/NestedModel/NestedModel.pdf&quot;&gt;nested model&lt;/a&gt; by Tamara Munzner.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;NB. I apologize in advance for the funny tone shift in the next section, I somehow wound up making it prescriptive rather than descriptive because it felt like a more natural way of relaying the information&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Domain Problem Characterization:&lt;/strong&gt; Before you can begin any visualization, you need to understand the problem you are trying to address with the visualization. If you are approaching data from a more exploratory perspective, then you should spend some time defining what you are interested in and what you expect as a result of your exploration.&lt;/p&gt;

&lt;p&gt;At this stage of the design process, you can start asking yourself:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Who will use the visualization and why?&lt;/li&gt;
  &lt;li&gt;What is their exposure to uncertainty?&lt;/li&gt;
  &lt;li&gt;Is uncertainty necessary for the user in accomplishing their task?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In Hullman’s survey, many of the respondents who are journalists discuss simplifying the message and omitting uncertainty deliberately. I would posit here that the journalists have implicitly or explicitly answered the questions above, deciding that uncertainty is not essential to the task of their users, which is to understand the narrative and main points of the article they are reading.&lt;/p&gt;

&lt;p&gt;In comparison, a design study researcher working with scientists should deliberately ask the scientists what types of uncertainty are important to their task at hand and why.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Operation and Data Type Abstraction:&lt;/strong&gt; After understanding the domain problem and the role that uncertainty could play in the ability of the users to achieve their tasks, you can shift your attention to understanding the data.
As stated in Munzner’s paper, this is the space to translate the tasks and problems from the first phase into the land of abstract computer science. In this phase, pay attention to the data. Does the data support your user’s task? Where is the data coming from? Has it been manipulated? Will you need to manipulate?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Visual Encoding and Interaction Design:&lt;/strong&gt; Going back to your initial task characterization, will you need to encode uncertainty in the data? What visual encoding will support the types of uncertainty that are present within the data or the processes associated with abstracting the data?&lt;/p&gt;

&lt;h3 id=&quot;still-uncertain&quot;&gt;Still Uncertain?&lt;/h3&gt;
&lt;p&gt;Even after writing this entry, I don’t think there can ever be a clear path to determining when and what types of uncertainty to visualize. The only thing I can say with certainty is that as a visualization designer it’s critical to understand the problem you are trying to solve and the motivation your users have to engage with and understand the visual encodings.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Further Reading:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/multiple-views-visualization-research-explained/- uncertainty-visualization-explained-67e7a73f031b&quot;&gt;the Medium series by Hullman and her colleague&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://flowingdata.com/2018/01/08/visualizing-the-uncertainty-in-data/&quot;&gt;a nice piece by FlowingData with examples of how to visualize Uncertainty&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.nytimes.com/2018/11/05/upshot/needle-election-night-2018-midterms.html&quot;&gt;the NYT explanation of their political needle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 15 Nov 2019 00:00:00 -0700</pubDate>
        <link>http://localhost:4000//2019/11/15/visualizing-uncertainty.html</link>
        <guid isPermaLink="true">http://localhost:4000//2019/11/15/visualizing-uncertainty.html</guid>
      </item>
    
      <item>
        <title>On Writing Abstracts</title>
        <description>&lt;p&gt;Since I can remember I have always doodled in class. It’s my method of paying attention to what the instructor is saying while letting my hands and imagination wander. You can imagine how vindicated I felt when studies came out supporting doodling as a method of improving concentration. Here is one &lt;a href=&quot;https://www.health.harvard.edu/blog/the-thinking-benefits-of-doodling-2016121510844&quot;&gt;article&lt;/a&gt; in case you’re curious.&lt;/p&gt;

&lt;p&gt;I haven’t actually doodled in a while because I was out of school for 6 years, and well, now that I am back, old habits die hard as the adage goes.
So while we were discussing methods for reviewing academic papers, a fellow classmate of mine mentioned scanning the abstract to determine the relevance of a paper, and think I nearly scoffed in response saying that I never read the abstract anymore. Which got me thinking, are we reading abstracts differently because of our astrological signs? Silly right? Ridiculous even, I know. But I couldn’t help doodling about it and eventually came up with this table…&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Drum roll please&lt;/em&gt; I present to you: Abstractology!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/../assets/images/abstractology.png&quot; alt=&quot;a chart on writing abstracts according to astrological signs&quot; class=&quot;responsive-image&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 13 Nov 2019 00:00:00 -0700</pubDate>
        <link>http://localhost:4000//2019/11/13/on-writing-abstracts.html</link>
        <guid isPermaLink="true">http://localhost:4000//2019/11/13/on-writing-abstracts.html</guid>
      </item>
    
  </channel>
</rss>