<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Haihan Lin, Derya Akbaba, Miriah Meyer, and Alexander Lex" />
  <title>Data Hunches: Incorporating Personal Knowledge into Visualizations</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Data Hunches: Incorporating Personal Knowledge into
Visualizations</h1>
<p class="author">Haihan Lin, Derya Akbaba, Miriah Meyer, and Alexander
Lex</p>
</header>
<p>While data-driven decision-making and reasoning is now considered the
gold standard across many fields such as business <span class="citation"
data-cites="brynjolfsson_rapid_2016">(Brynjolfsson and McElheran
2016)</span>, sports <span class="citation"
data-cites="troilo_perception_2016">(Troilo et al. 2016)</span>, and
science <span class="citation"
data-cites="nationalsciencefoundation_nsf&#39;s">(Foundation,
n.d.)</span>, data workers are also aware of the incompleteness and
imperfections of data <span class="citation"
data-cites="boukhelifa_how_2017 muller_how_2019">(Boukhelifa et al.
2017; Muller et al. 2019)</span>. In scientific data analysis, for
example, caveats about the data are often captured in (digital or paper)
lab notebooks, as comments in analysis scripts, and as datasheets
recorded alongside a dataset <span class="citation"
data-cites="gebru_datasheets_2021">(Gebru et al. 2021)</span>, and they
are discussed with colleagues in lab meetings, and reported to a general
audience in methods sections of scientific papers.</p>
<p>These processes, however, detach a person’s knowledge about caveats
to the data from the tools in which the data is analyzed. For example,
if a caveat about the data is recorded in a graduate student’s lab
notebook, their successor who is asked to re-analyze the data may not
have access to the notes and may interpret the data differently. Even if
a caveat is noted in the methods section of a paper, a casual reader
might skip that section and misinterpret a visualization of the
data.</p>
<p>We encountered this challenge in a design study where we collaborated
with clinicians who analyze data about blood transfusions to improve
patient outcomes and reduce the use of valuable blood-bank
resources <span class="citation" data-cites="lin_sanguine:_2021">(Lin et
al. 2021)</span>. When we showed a clinical collaborator a prototype of
our visualization tool, he expressed concern about what he saw in the
data: that the amount of recycled blood—a patient’s own blood that is
reused during surgery—was much lower than he expected. In his
experience, almost all surgeons make extensive use of blood recycling;
he had a hunch that the low blood recycling values were due to the data
frequently not being recorded during surgeries. A second collaborator
focusing on patient blood management was promoting a more data-driven
approach in his workplace and worried that when clinicians saw these
discrepancies, they would lose trust in the visualization tool. Despite
these concerns, we had no way of recording and communicating the
clinicians’ hunches in the visualization.</p>
<p>Just like in this example, we frequently find that interactions with
a visualization tool trigger experts to express knowledge about problems
with data, but that these tools leave few options for them to
communicate that knowledge. This knowledge is personal and not available
to others, a phenomenon reported in other design studies <span
class="citation"
data-cites="mccurdy_framework_2019 nowak_designing_2020 panagiotidou_implicit_2021">(Mccurdy,
Gerdes, and Meyer 2019; Nowak, Bartram, and Haegeli 2020; Panagiotidou
et al. 2021)</span>. However, what if experts could record their hunches
directly in a visualization tool in a way that allowed others to
interpret the data alongside their hunches? What if a visualization tool
supported—and encouraged—the explicit incorporation of expert knowledge
during data analysis?</p>
<p>In this paper, we address these questions by proposing a new concept,
<em>data hunches</em>, to describe the knowledge that analysts bring to
their data analysis process that augments and complements their
perception of the data, and in turn becomes part of their
interpretations as demonstrated in Figure <a href="#fig:teaser"
data-reference-type="ref" data-reference="fig:teaser">[fig:teaser]</a>.
Data hunches are personal knowledge about caveats to the data, such as
knowledge about implicit errors <span class="citation"
data-cites="mccurdy_framework_2019">(Mccurdy, Gerdes, and Meyer
2019)</span> or ambiguities <span class="citation"
data-cites="nowak_designing_2020">(Nowak, Bartram, and Haegeli
2020)</span>. We argue that conceptualizing data hunches provides a new
perspective on how to design visual analysis tools for expert,
collaborative settings, allowing for the sharing of knowledge about the
ways that data is imperfect, partial, and uncertain. This new
perspective opens design possibilities for how we might build
visualization tools that support both the recording and communicating of
hunches.</p>
<p>To this end, our work includes three core contributions:</p>
<ul>
<li><p><strong>A conceptualization of data hunches:</strong> We define
the term <em>data hunches</em> and discuss its relationship to
uncertainty, elevating the role of personal knowledge in visual data
analysis.</p></li>
<li><p><strong>An exploration of ways to record and communicate data
hunches:</strong> We demonstrate how data hunches can be recorded and
communicated within a visualization context using visual techniques to
facilitate collaboration.</p></li>
<li><p><strong>A set of design recommendations for data
hunches:</strong> We reflect on design and ethical considerations for
supporting data hunches within visualization systems.</p></li>
</ul>
<p>We speculate how recording and communicating data hunches could be
implemented through a demo tool, available at <a
href="https://vdl.sci.utah.edu/data-hunch/"
class="uri">https://vdl.sci.utah.edu/data-hunch/</a>. For transparency
and rigor, we include a brief discussion of our methodology in
Section <a href="#sec:methodology" data-reference-type="ref"
data-reference="sec:methodology">7</a>. We discuss the potential of data
hunches, for both good and bad outcomes in Section <a
href="#sec:discussion" data-reference-type="ref"
data-reference="sec:discussion">9</a>. Despite open questions about how
to design for data hunches in ethical and usable ways, we consider this
work a step toward a wealth of productive opportunities for valuing and
including personal knowledge in visual data analysis.</p>
<h1 id="uncertainty">Uncertainty</h1>
<p>Measurement errors, modeling assumptions, heterogeneous data
recording methods, and missing context are just some of the ways in
which values stored in a dataset are neither a perfect nor complete view
of a phenomenon in the world. The visualization community has a long
history of researching methods to characterize, quantify, and visualize
the limitations of data under the heading of <em>uncertainty</em>.
Within this literature, explicit definitions for uncertainty are sparse,
with the definitions that do exist covering a range of interpretations.
For example, Hullman refers to uncertainty as “the possibility that the
observed data or model predictions could take on a set of possible
values” <span class="citation" data-cites="hullman_why_2020">(Jessica
Hullman 2020)</span>, whereas Bonneau et al state that “uncertainty is
the lack of information” <span class="citation"
data-cites="bonneau_overview_2014">(Bonneau et al. 2014)</span>. Fields
outside of visualization add additional interpretations of the term,
such as Walker et al.’s general notion of uncertainty as “any deviation
from the unachievable ideal of completely deterministic knowledge of the
relevant system” <span class="citation"
data-cites="walker_defining_2003">(Walker et al. 2003)</span>, and
Covitt et al.’s experiential definition of uncertainty as the “ways in
which scientists recognize and analyze limits in their studies and
conclusions” <span class="citation"
data-cites="covitt_untangling_2022">(Covitt and Anderson
2022)</span>.</p>
<p>Researchers have openly acknowledged the ill-defined nature of
uncertainty, such as Boukhelifa et al.’s statement that “there is no
unified single definition of uncertainty across all domains. The general
consensus is that there are different meanings and that the term itself
encapsulates many concepts” <span class="citation"
data-cites="boukhelifa_how_2017">(Boukhelifa et al. 2017)</span>.
Brodlie et al. go further and argue that the lack of a clear, consensus
definition has held the field back: “the self-referential problem of
uncertainty about uncertainty terminology has been a notable stumbling
block in this avenue of inquiry” <span class="citation"
data-cites="brodlie_review_2012">(Brodlie, Allendes Osorio, and Lopes
2012)</span>.</p>
<p>In this paper, we do not attempt to rectify the uncertainty about
uncertainty. Rather, we point out the difficulty of precisely
positioning theoretical perspectives in relation to existing uncertainty
literature. Despite this challenge, we situate data hunches within the
visualization uncertainty literature because this body of work has
focused on understanding and characterizing how people, visualizations,
and imperfect and partial data come together. More specifically, the
uncertainty literature focuses on the ways that data is limited
representations of the world, and how people (can) become aware of these
limitations. Such perspective is in contrast to other visualization
research threads that focus on expert knowledge more broadly, such as
work on insight that considers different types of expert knowledge that
impacts insight generation <span class="citation"
data-cites="karer_insight_2021">(Karer, Hagen, and Lehmann 2021)</span>.
In this section, we briefly summarize the literature on quantitative and
qualitative uncertainty, and argue that data hunches complement the
existing work in this area.</p>
<h2 id="quantitative-uncertainty">Quantitative Uncertainty</h2>
<p>Researchers provide a variety of characterizations of uncertainty
through descriptions of the many ways that data can be uncertain. Potter
et al. <span class="citation"
data-cites="potter_quantification_2012">(Kristin Potter, Rosen, and
Johnson 2012)</span> use a characterization from computational sciences
that describes <em>epistemic</em> versus <em>aleatoric</em> uncertainty,
with the former describing the ways in which a lack of knowledge about
and from the data induce a computationally unknowable uncertainty, and
the latter encompassing data limitations that can be assumed and modeled
statistically. Padilla et al. compare <em>direct quantitative</em>
uncertainties and <em>indirect qualitative</em> uncertainties <span
class="citation" data-cites="padilla_uncertain_2021">(Lace M. K. Padilla
et al. 2021)</span>. In this framing, direct uncertainties are
quantifiable expressions such as confidence intervals and probability
distributions, whereas indirect uncertainties can be expressed only
qualitatively. Direct, quantifiable expressions of uncertainty are
typically computed from sources of imperfections and partialities,
including limited data collection resources, such as not being able to
sample every person in a population of interest; limited measurement
capabilities, such as the precision of an instrument; or limited
knowledge about the future, such as the unpredictability of forecasting
weather <span class="citation"
data-cites="thomson_typology_2005">(Thomson et al. 2005)</span>.</p>
<p>The visualization community has historically focused on developing
and testing methods for visualizing quantifiable uncertainty <span
class="citation"
data-cites="padilla_powerful_2020 bonneau_overview_2014 potter_quantification_2012">(Lace
M. K. Padilla, Creem-Regehr, and Thompson 2020; Bonneau et al. 2014;
Kristin Potter, Rosen, and Johnson 2012)</span>. Some approaches attempt
to intuitively encode uncertainty through modifications of a data item’s
graphical mark using quantile dot plots <span class="citation"
data-cites="padilla_uncertain_2021">(Lace M. K. Padilla et al.
2021)</span>, glyphs <span class="citation"
data-cites="johnson_next_2003 wittenbrink_glyphs_1996 padilla_powerful_2020">(Johnson
and Sanderson 2003; Wittenbrink, Pang, and Lodha 1996; Lace M. K.
Padilla, Creem-Regehr, and Thompson 2020)</span>, or value-suppressed
color schemes <span class="citation"
data-cites="correll_value-suppressing_2018">(Correll, Moritz, and Heer
2018)</span>. Other approaches have instead explored visual
representations that directly display summary statistics <span
class="citation"
data-cites="potter_visualizing_2010 correll_error_2014 potter_interactive_2012">(K.
Potter et al. 2010; Correll and Gleicher 2014; Kristin Potter et al.
2012)</span> or use animations showing hypothetical outcomes <span
class="citation" data-cites="hullman_hypothetical_2015">(Jessica
Hullman, Resnick, and Adar 2015)</span>. Researchers have also developed
uncertainty-specific evaluation techniques, such as eliciting users’
internal models of probability distributions, recording the effects of
uncertainty on decision-making, and assessing participants’ sense of
confidence after viewing uncertainty visualizations <span
class="citation" data-cites="hullman_pursuit_2019">(J. Hullman et al.
2019)</span>.</p>
<p>The community’s characterization of what types of uncertainty are
quantifiable would seemingly place our blood-reuse example in Section 1
as something that could be quantified, a limitation of the measurement
capabilities. In principle, we could attempt to model and quantify this
limitation, but any metric is likely to be grossly inaccurate because of
the abstracted nature of the knowledge about the imperfections, a point
raised by Thomson et al.: “In addition to uncertain measures, analysts
are concerned with abstract uncertainties such as the credibility of a
particular source or the completeness of a set of information. As the
uncertainty becomes more abstract, it is more difficult to quantify,
represent, and understand” <span class="citation"
data-cites="thomson_typology_2005">(Thomson et al. 2005)</span>.
Instead, researchers adopt different perspectives for abstract sources
of uncertainty—qualitative perspectives—that focus on the knowledge
people have about the limitations of data.</p>
<h2 id="qualitative-uncertainty">Qualitative Uncertainty</h2>
<p>Qualitative uncertainty—also referred to as indirect or epistemic
uncertainty—has been described as “the quality of knowledge concerning
how effectively facts, numbers, or hypotheses represent reality” <span
class="citation" data-cites="padilla_uncertain_2021">(Lace M. K. Padilla
et al. 2021)</span>. Definitions of qualitative uncertainty make
explicit references to knowledge, shifting the emphasis from exploitable
information about the data, to inaccessible subjective knowledge:
“Epistemic uncertainty generally, but not always, concerns past or
present phenomena that we currently don’t know but could, at least in
theory, know or establish” <span class="citation"
data-cites="vanderbles_communicating_2019">(van der Bles et al.
2019)</span>. In contrast to quantitative uncertainty, qualitative
uncertainty is not easily quantified, and is generally conveyed through
“caveats about data” <span class="citation"
data-cites="vanderbles_communicating_2019">(van der Bles et al.
2019)</span>.</p>
<p>The sources of qualitative uncertainty stem from the same
imperfections and partialities that metrics for quantifying uncertainty
pertain to. Boukhelifa et al. <span class="citation"
data-cites="boukhelifa_how_2017">(Boukhelifa et al. 2017)</span>
classify these sources as imperfect, messy, and missing <em>data</em>;
imperfect and limited <em>models</em>; (approximate) digital
representations of data in a visualization <em>interface</em>; and
<em>cognitive</em> differences between interpretations from individual
analysts. Most relevant for the work in this paper are sources of
qualitative uncertainty from data, defined by McCurdy et al. as
<em>implicit error</em>: “a type of measurement error that is inherent
to a dataset but not explicitly recorded, yet is accounted for
qualitatively by experts during analysis, based on their implicit domain
knowledge” <span class="citation"
data-cites="mccurdy_framework_2019">(Mccurdy, Gerdes, and Meyer
2019)</span>.</p>
<p>The predominate way that visualization designers encode qualitative
expressions of uncertainty is through text-based annotations. In her
interview study with visualization practitioners, Hullman reports that
“uncertainty as a qualitative expression of a gap in knowledge came up
in most interviews with interviewees as well as several survey
responses. 62% of survey respondents had used text to warn their viewers
of the potential for uncertainty in results” <span class="citation"
data-cites="hullman_why_2020">(Jessica Hullman 2020)</span>. Other
approaches use visual approaches to communicate qualitative uncertainty,
such as the use of perceptually imprecise visual encoding channels like
sketchiness <span class="citation"
data-cites="boukhelifa_evaluating_2012">(Boukhelifa et al. 2012)</span>
or glyphs <span class="citation"
data-cites="nowak_designing_2020">(Nowak, Bartram, and Haegeli
2020)</span>. A different approach taken in both the visualization and
machine learning communities is to explicitly expose information about
the data collection process, providing analysts with contextual
information that allows them to incorporate personal knowledge about
potential shortcomings of the data during their interpretations <span
class="citation"
data-cites="panagiotidou_implicit_2021 gebru_datasheets_2021 arnold_factsheets:_2019">(Panagiotidou
et al. 2021; Gebru et al. 2021; Arnold et al. 2019)</span>.</p>
<p>Several visualization systems explore ways for recording expert
knowledge about qualitative sources of uncertainty. For example, in
their tool for supporting public health experts, McCurdy et al. <span
class="citation" data-cites="mccurdy_framework_2019">(Mccurdy, Gerdes,
and Meyer 2019)</span> designed a template with structured questions
that enabled the experts to record what they knew about implicit errors
in the data. The recorded results were marked on the visualizations with
glyphs that provided annotations when clicked. Similarly, Franke et
al. <span class="citation" data-cites="franke_confidence_2019">(Franke
et al. 2019)</span> collected confidence about data sources from
historians through a web interface. These varying levels of confidence
were then presented alongside other data in a hierarchical tree view,
representing the distribution of confidence along different dimensions
of the data source in question.</p>
<p>These two examples demonstrate that experts <em>know</em> about
limitations of their data; that the sources of uncertainty can be known.
This, however, is in contrast to existing definitions of qualitative
uncertainty that position it as something unknowable: “epistemic
uncertainty describes uncertainties due to lack of knowledge and limited
data which could, in principle, be known, but in practice are not” <span
class="citation" data-cites="potter_quantification_2012">(Kristin
Potter, Rosen, and Johnson 2012)</span>. This focus on the unknowable
also appears in more general uncertainty characterizations <span
class="citation" data-cites="bonneau_overview_2014">(Bonneau et al.
2014)</span>. This contradiction leads us to ask the question: unknown
by whom?</p>
<p>The work we present in this paper is a significant shift in how we
think about designing for qualitative uncertainty. Data hunches frame
the knowledge about sources of uncertainty away from the visualization
tool designers, to the experts who conduct the analysis. The concept of
data hunches is an explicit acknowledgment that many sources of
qualitative uncertainty are in fact known—known to the experts who can
articulate the knowledge when triggered by their interactions with a
visualization tool. This shift complements the visualization community’s
perspectives on uncertainty by focusing on knowledge about sources of
uncertainty, and thus opening up opportunities to design new ways that
visualizations can support recording and communicating this knowledge
during data analysis.</p>
<h1 id="sec:data_hunches">Data Hunches</h1>
<p>Our community’s current framing of uncertainty implies that data
workers and tool builders are responsible for identifying,
characterizing, and quantifying sources of uncertainty from data. Data
hunches instead acknowledge and incorporate experts who come to data
analysis with deep knowledge about the limitations of their data. As a
complementary perspective, data hunches focus on knowledge about data,
capture that knowledge from a diverse set of stakeholders, and are
embeddable in the analysis process (instead of the data curation
pipeline). We argue that this perspective offers a breadth of new
opportunities for recording and communicating data hunches in support of
richer data analysis.</p>
<p>Through data hunches, we elevate the role that personal knowledge of
the data plays in the process of understanding and analyzing it. More
precisely, <strong>we define <em>data hunches</em> as an analyst’s
knowledge about how and why the data is an imperfect and partial
representation of the phenomena of interest.</strong> These hunches can
range from the abstract—expressing concern about the validity of the
data set—to the concrete—expressing a numerical value that is closer to
the phenomenon of interest than the measured data. The scope of a data
hunch can be individual data points, a complete dataset, or anything in
between. Data hunches emerge when an analyst interacts with the data,
triggering reflection about the ways the data is imperfect and partial
based upon their inherent knowledge about the data collection process,
domain, and more. A data hunch can be based on the missing context
necessary to fully comprehend the phenomenon, discrepancies between a
mental model and data, opinions on the quality of the data generation
process, and so on. Data hunches are knowledge about sources of
qualitative uncertainty. During data analysis, data hunches influence an
analyst’s interpretation of the data, derived knowledge, and decisions
made.</p>
<p>We argue that data hunches are prevalent, but often implicit, in data
analysis, and as important as the data itself. The knowledge experts
bring to data analysis is a vital component of data-driven
decision-making <span class="citation"
data-cites="morgan_use_2014 karer_insight_2021">(Morgan 2014; Karer,
Hagen, and Lehmann 2021)</span>; however, such knowledge is often
recorded outside of visual analysis tools. This disconnect then requires
mental gymnastics on the part of an analyst to incorporate back into the
data analysis process, if it is not overlooked completely. In this
paper, we envision that a set of tools that fully utilize what
visualization can offer will provide a more visual and intuitive
representation of experts’ knowledge in visualizations. Using data and
data hunches in tandem supports a richer representation of a phenomenon,
leading potentially to improved analysis. By acknowledging and naming
data hunches, we aim to elevate the potential for personal knowledge to
actively and explicitly contribute to data analysis.</p>
<p>We purposefully scope data hunches for use within collaborative,
expert settings for both pragmatic and ethical reasons. Pragmatically,
previous work on collaborative visualizations highlights the value of
designing tools that support sharing of expert knowledge. In the context
of collaborative analysis sessions, Mahyar et al. <span class="citation"
data-cites="mahyar_note-taking_2012">(Mahyar, Sarvghad, and Tory
2012)</span> showed the importance of recording visualizations and note
taking in collaborative visual analysis. Similarly, Walny et al. <span
class="citation" data-cites="walny_visual_2011">(J. Walny et al.
2011)</span> studied the use of data visualizations on whiteboards in
corporate offices and found that visualizations as sketches promote team
discussions. In another example of data science workflows that utilize
computational notebooks, Wang et al. <span class="citation"
data-cites="wang_how_2019">(Wang et al. 2019)</span> found that data
scientists annotated screenshots of visualizations when collaborating as
a way to communicate limitations of a tool. Ethically, scoping data
hunches to collaborative expert settings reduces potential harm as we
expect experts collaborating with peers to recorded well-reasoned and
nuanced hunches. However, experts can still be biased, and data hunches
may help to reinforce biases even further. We believe that peer-review
tools, such as comments or ratings, may be useful to mitigate the risk
of reinforcing biases, yet acknowledge that more research on the topic
is necessary. We discuss these and other issues further in Section <a
href="#sec:discussion" data-reference-type="ref"
data-reference="sec:discussion">9</a>.</p>
<p>By identifying data hunches as productive and insightful expert
knowledge, we can re-interpret past work on collaborative visualization
tools with this framing. For example, a visualization designer can
incorporate commenting and discussion features to promote
externalization of data hunches <span class="citation"
data-cites="mccurdy_framework_2019 heer_voyagers_2009">(Mccurdy, Gerdes,
and Meyer 2019; Heer, Viégas, and Wattenberg 2009)</span>; apply
provenance tracking to record actions they took based on hunches to
wrangle the data <span class="citation"
data-cites="feng_hindsight:_2017 cutler_trrack:_2020 gadhave_predicting_2021 gadhave_reusing_2022">(Feng
et al. 2017; Cutler, Gadhave, and Lex 2020; Gadhave et al. 2021;
Gadhave, Cutler, and Lex 2022)</span>; use visualization techniques like
linked views and visualization states to show a collection of data
hunches <span class="citation"
data-cites="viegas_manyeyes:_2007 mathisen_insideinsights:_2019 isenberg_collaborative_2011">(Viegas
et al. 2007; Mathisen et al. 2019; Isenberg et al. 2011)</span>. We see
a wealth of opportunities for incorporating data hunches into old and
new ways of visually analyzing data.</p>
<div class="figure*">
<p><embed src="figures/externalize_design_space.pdf" /></p>
<p><span id="fig:externalize_design_space"
label="fig:externalize_design_space"></span></p>
</div>
<h1 id="types-of-data-hunches">Types of Data Hunches</h1>
<p>In our development of data hunch classifications, we listed all the
data hunches we encountered in our previous design studies, brainstormed
other forms of data hunches that may surface in data analysis, and
generalized them based on whether they are qualitative or quantitative,
the specificity of the hunches, and the forms they take if expressed. We
identify three types of data hunches in support of determining suitable
methods for reporting and communicating expert knowledge about
limitations of data.</p>
<p><strong>Assessment Hunches:</strong> Assessment data hunches speak to
the trustworthiness or quality of a dataset or individual data items, or
simply provide context. Assessment hunches can take different forms,
ranging from ratings (thumbs-up/down, numerical scores, etc.), to
written comments about data items or datasets.</p>
<p><strong>Structural Hunches:</strong> Structural data hunches state
that certain data points or relationships should not be included in the
dataset (exclusion) or that a data item or relationship is missing
(inclusion). In a network dataset, for example, an inclusion data hunch
could be used to indicate that an edge is missing. For many data types,
inclusion hunches should also be combined with an estimate of a value of
the included hunch. For example, when indicating that an item is missing
from a dataset, the data hunch could also contain an estimate of the
value of the item.</p>
<p><strong>Value Hunches:</strong> Value hunches make a statement about
how a specific data value should be different from what is recorded in
the dataset. Value hunches apply equally to numerical, categorical, and
textual/label data. For example, a value hunch for a category could
state that an item should be in category A instead of category B.</p>
<p>For practical reasons, we found it useful to further distinguish
three methods of expressing value hunches, reflecting different levels
of “precision” about a value hunch. <em>Directional Hunches</em> express
that values should be different (higher or lower) from the recorded
value without giving a specific value. They are a middle ground between
assessment hunches, which make no statement about directionality, and
hunches that give estimates for actual values. <em>Specific Value
Hunches</em> express exactly how values in a dataset should be
different. For example, a value data hunch could state that the value
encoded by a bar chart should be 20 instead of 12. <em>Value Range
Hunches</em> acknowledge uncertainty about the value to be specified.
Instead of expressing a specific value, they state that a value should
be within a certain range. For example, a range hunch could state that
the value of a bar should be between 18 and 22 instead of 12. We
acknowledge that different subtypes of any of the higher level types of
data hunches could be useful in different contexts.</p>
<p>All these types of data hunches can be expressed with different
specificity. For example, a value data hunch could apply to a single
point (this should be twice as much), to a few data points (all of these
items should be twice as high), or to the whole dataset (all data points
should be twice as high). These different types of data hunches also
establish that hunches may not always be precise, supporting analysts to
record some data hunches across varying levels of knowledge. In the next
section, we discuss how we design with data hunches in mind. With an
emphasis on visual methods, knowledge about sources of qualitative
uncertainty can be represented through graphical elements and
interpreted context of the data.</p>
<h1 id="sec:recording">Recording Data Hunches</h1>
<p>A key aspect of data hunches is that they are expressed during
analysis by a diverse set of stakeholders. Hence, visualizations of the
data are the ideal medium to express, record, and consume data hunches.
In this section, we explore the set of approaches that can be used for
recording data hunches on top of a visualization.</p>
<div class="figure*">
<p><embed src="figures/all_dh_prototype.pdf" /></p>
</div>
<h2 id="data-space">Data Space</h2>
<p>A basic method to record a data hunch is to manipulate the data in
data space: before the data has been mapped to a visual element. We
consider form-based manipulation and model-based manipulation as the two
main methods for recording data hunches in data space.
<strong>Form-based manipulation</strong>, shown in Figure <a
href="#fig:externalize_design_space" data-reference-type="ref"
data-reference="fig:externalize_design_space">[fig:externalize_design_space]</a>a,
is concerned with inputting a data value or an attribute of the data
point through a form, a table, etc., and is suitable for data hunches
for specific data items. <strong>Model-based manipulation</strong>,
illustrated in Figure <a href="#fig:externalize_design_space"
data-reference-type="ref"
data-reference="fig:externalize_design_space">[fig:externalize_design_space]</a>b,
uses a model to bulk-input or edit data values, e.g., through a
mathematical function. Note that manipulating the data in data space
does not imply that the original data is overwritten.</p>
<p>Previous works have explored ways to express models and values to
record knowledge in visualizations. Marasoiu et al. <span
class="citation" data-cites="marasoiu_clarifying_2016">(Marasoiu et al.
2016)</span>, for example, presented an interface that allows users to
sketch models, which then generates data points based on the sketch, as
a way to facilitate communication between customers and analysts. Romat
et al. <span class="citation" data-cites="romat_activeink:_2019">(Romat
et al. 2019)</span> included data editing in their digital ink
externalization system, a functionality requested by participants.
Although this functionality was added post facto, it illustrates a
preference for editing data directly in systems.</p>
<p>Data space is not well suited to communicate the data hunches that
have been recorded in the context of visualizations, as e.g., a tabular
representation of data hunches would be detached from the visualization
of the data. Instead, designers will have to consider methods to
visualize data hunches provided in data space in visual space.</p>
<h2 id="visual-space">Visual Space</h2>
<p>Recording data hunches in visual space on top of a visualization
provides a direct connection between a data hunch and the visualization.
Analysts can think about the data hunch in visual terms as they
manipulate it, and consider other data points that are visualized while
recording their hunch. Another key benefit of recording data hunches in
visual space is that, to a large extent, the same encodings can be used
for recording and communicating data hunches. We suggest two techniques
for recording data hunches in visual space: free-form sketching and
direct manipulation.</p>
<p><strong>Free-form sketching</strong> refers to adding visual elements
directly to a visualization, using approaches such as pen/mouse-based
sketching, or adding elements to a visualization using functionality
similar to a drawing program (Figure <a
href="#fig:externalize_design_space" data-reference-type="ref"
data-reference="fig:externalize_design_space">[fig:externalize_design_space]</a>c).
The technique provides freedom for analysts to express their data hunch
in the way they see fit and can record a variety of data hunches,
including structural exclusion through crossing out data points,
value/directionality (e.g., a value should be higher in reality) through
drawing an arrow, categorical value through shading an area in a color,
and value range through drawing an area where a value is expected to be.
Visual markups have been used for note taking and communicating though
process in visualizations <span class="citation"
data-cites="kim_inking_2019 marasoiu_clarifying_2016 romat_activeink:_2019">(Kim
et al. 2019; Marasoiu et al. 2016; Romat et al. 2019)</span>, as well as
conversation starters <span class="citation"
data-cites="willett_understanding_2015">(Willett, Goffin, and Isenberg
2015)</span>. The process of graphical externalization helps with the
understanding of and reasoning about visual information <span
class="citation" data-cites="hegarty_individual_1997">(Hegarty and
Steinhoff 1997)</span> and supports reading and reflecting on the
visualization <span class="citation"
data-cites="walny_active_2018 kim_explaining_2017 aisch_you_2015">(Jagoda
Walny et al. 2018; Kim, Reinecke, and Hullman 2017; Aisch, Cox, and
Quealy 2015)</span>. A downside of markup is that it cannot (easily) be
converted into structured data, and hence is only connected to the
visualization, but not to the underlying data, making reuse of these
hunches in other visualizations of the same dataset exceedingly
difficult.</p>
<p><strong>Direct manipulation</strong>, illustrated in Figure <a
href="#fig:externalize_design_space" data-reference-type="ref"
data-reference="fig:externalize_design_space">[fig:externalize_design_space]</a>d,
involves moving, resizing, removing, adding, or otherwise changing parts
of the visualization that encode data. While restricting analysts to the
marks and channels of the visualization, direct manipulations offer
beneficial affordances: dragging a bar element is easier with a mouse
than sketching a new bar, for example. Manipulated marks are also
straightforward to translate into data space. Previous works have
suggested direct manipulation on visual encodings is a viable way to
edit data and provide visual demonstrations of thought processes.
Baudel <span class="citation"
data-cites="baudel_information_2006">(Baudel 2006)</span> presented
editing single or groups of data items in a dataset using graphical
manipulations in data visualizations. Saket et al. <span
class="citation" data-cites="saket_visualization_2017">(Saket et al.
2017)</span> used graphical manipulation, through repositioning,
resizing, and recoloring marks in visualizations, to help users express
their expected visualization with increments in direct manipulations,
and in turn, the system suggests visual transformations. A drawback of
direct manipulation is that each possible manipulation has to be
designed and implemented for each chart type, in contrast to free-form
sketching, which can be implemented once and re-used for all types of
hunches and charts.</p>
<h2 id="abstract-space">Abstract Space</h2>
<p>Assessment data hunches can be expressed only through text, comments,
or ratings. For example, an analyst might know that a data source is
unreliable, but might not have a concrete idea on what the true data
should be. To record such a hunch, they want to add comments to the data
and the data visualization. Such hunches are recorded in “abstract
space”, as they do not directly suggest a different structure or value.
We identify two methods through which hunches can be recorded in
abstract space: <strong>structured elicitation</strong> and
<strong>textual annotations</strong> (in addition to e.g., hand-writing
using free-form sketching features).</p>
<p>Structured elicitation (Figure <a
href="#fig:externalize_design_space" data-reference-type="ref"
data-reference="fig:externalize_design_space">[fig:externalize_design_space]</a>e)
uses form-based UI elements, ratings, and up/down votes, whereas textual
annotations (Figure <a href="#fig:externalize_design_space"
data-reference-type="ref"
data-reference="fig:externalize_design_space">[fig:externalize_design_space]</a>f)
are free-formed notes. Previous works have explored the use of rating,
structured form, and textual annotations in data visualizations. Quispel
&amp; Maes <span class="citation"
data-cites="quispel_would_2014">(Quispel and Maes 2014)</span> used
ratings to investigate preferences of visualization types between groups
of people. McCurdy et al. <span class="citation"
data-cites="mccurdy_framework_2019">(Mccurdy, Gerdes, and Meyer
2019)</span> used structured forms to elicit data hunches from domain
experts, and Goyal et al. <span class="citation"
data-cites="goyal_effects_2013">(Goyal, Leshed, and Fussell 2013)</span>
offered more freedom to users by allowing them to use a notepad for
free-form notes during their experiment. Structured elicitation is
different from form-based manipulation in data space: although both can
use forms, structured elicitation is about assessment, whereas
form-based manipulation is used to express concrete hunches in data
space.</p>
<h1 id="sec:guidelines">Guidelines for Designing for Data Hunches</h1>
<p>To demonstrate the feasibility of the techniques we proposed in
Section <a href="#sec:recording" data-reference-type="ref"
data-reference="sec:recording">4</a> and to explore possibilities of
communicating and recording data hunches, we developed a prototype,
shown in Figure <a href="#fig:all_dh_prototype"
data-reference-type="ref"
data-reference="fig:all_dh_prototype">[fig:all_dh_prototype]</a>,
allowing users to record their data hunches on a simple bar chart. As
described in Section <a href="#sec:methodology"
data-reference-type="ref" data-reference="sec:methodology">7</a>, we
used an iterative design process to develop the prototype. We describe
insights gleaned from this process for designing visualizations that
support recording and displaying data hunches in the form of design
guidelines.</p>
<h4 id="do-not-change-the-original-data."><strong>Do not change the
original data.</strong></h4>
<p>Techniques to express and communicate data hunches aim to enable
analysts to express their knowledge about the data, but not to alter the
dataset. Data hunches and original data are different entities and
should be clearly separated, to both avoid confusion about the
difference between data and data hunch and to retain the integrity of
the original data. Data hunches are also valuable only in the context of
the recorded data that they refer to. For example, for a value hunch
expressed in Figure <a href="#fig:all_dh_prototype"
data-reference-type="ref"
data-reference="fig:all_dh_prototype">[fig:all_dh_prototype]</a>h, we
use a sketchy font and arrows to indicate a different value from the
original data, and place the value hunch next to the original value.
Furthermore, while transparently expressing data hunches, such as doubts
or ideas about what a data point should be, are valuable contributions
to the analysis process, editing data can be considered deceptive or
even fraudulent.</p>
<p>From a technical aspect, designers should treat recorded data hunches
as another dataset completely that only references (elements in) the
original dataset. In our prototype, for example, data hunches are
recorded as a separate dataset, which is shown in a table next to the
visualization (Figure <a href="#fig:all_dh_prototype"
data-reference-type="ref"
data-reference="fig:all_dh_prototype">[fig:all_dh_prototype]</a>m). An
unfortunate consequence of separating hunches from data is that
off-the-shelf visualization systems and libraries are unlikely to make
it easy to render data hunches in addition to the underlying data.</p>
<h4 id="make-data-hunches-distinct."><strong>Make data hunches
distinct.</strong></h4>
<p>Consistent with our arguments about not changing the original data,
data hunches also need to be clearly distinguishable from the original
data within the visualizations. Furthermore, the encoding used for data
hunches should not only be distinct from the primary encoding, but also
should clearly communicate that what is shown is not the original
data.</p>
<p>In our prototype, we use sketchy rendering <span class="citation"
data-cites="wood_sketchy_2012">(Wood et al. 2012)</span> for visual
elements and handwriting-style fonts to make data hunches discernible
from the crisp, clean lines of the original visualizations (see
Figure <a href="#fig:all_dh_prototype" data-reference-type="ref"
data-reference="fig:all_dh_prototype">[fig:all_dh_prototype]</a>). The
goal of using sketchiness was to make it obvious, even to first time
users, that data hunches are not original data but that instead they
represent people’s thoughts and knowledge. Wood et al., for example,
speculate that “sketchy [..] visualization has a role to play in
constructing visualization narratives where an author’s voice is
important” <span class="citation" data-cites="wood_sketchy_2012">(Wood
et al. 2012)</span>. In our first designs, shown in Figure <a
href="#fig:non-sketchy-design" data-reference-type="ref"
data-reference="fig:non-sketchy-design">1</a>, we attempted to render
data hunches using a different color, and experimented with gradients
and blur to communicate uncertainty and ranges. However, we abandoned
this design as we realized that it could lead to confusion, as the marks
could be interpreted as belonging to the original data. To avoid this
confusion, we developed a rule we applied throughout our design process
that all data hunches should look as if they were hand-sketched or
written on top of a visualization, to emphasize the humanness of the
hunches.</p>
<p>We do not argue that sketchiness is the only, or even the best choice
to communicate data hunches. Other designs, tailored to other
visualization techniques and affordances, are conceivable. This
reasoning applies to all the implemented features we describe in this
section.</p>
<p>Another consideration is to be mindful of how disruptive data hunch
encodings could be when placed over the original visualizations. The
original visualizations must remain visible to properly interpret data
hunches. For example, in an early design, we rendered a bar representing
a larger data hunch over the original bar. We abandoned this idea in
favor of hatched bars that ensure that the underlying data point remains
visible.</p>
<figure>
<img src="figures/non-sketchy-design.png" id="fig:non-sketchy-design"
alt="Original, non-sketchy design for data hunches. While the data hunches were distinguishable from the original data by color, the distinction was not immediately obvious and could be confused with additional data values that are part of the original data. Hence, we abandoned this design in favor of sketchy renderings." />
<figcaption aria-hidden="true">Original, non-sketchy design for data
hunches. While the data hunches were distinguishable from the original
data by color, the distinction was not immediately obvious and could be
confused with additional data values that are part of the original data.
Hence, we abandoned this design in favor of sketchy
renderings.</figcaption>
</figure>
<p><span id="fig:non-sketchy-design"
label="fig:non-sketchy-design"></span></p>
<h4 id="but-make-data-hunches-similar."><strong>But, make data hunches
similar.</strong></h4>
<p>Data hunches should use the same or similar visual encodings as the
visualizations of the original data. While this guideline seems like a
direct contradiction of the guideline on making data hunches distinct,
we believe that data hunches and the original data should be read
together without the need for mental conversion. For example, a value
data hunch could be expressed as a written numerical value on top of a
bar chart. However, we argue that this would make it difficult for an
analyst to judge the relative differences between the original value and
the data hunch. Comparisons are easier if both are expressed using the
same visual channel (size/position in the case of a bar chart). Our
prototype uses sketchy bars on top of regular bars for numerical
specific value hunches (Figure <a href="#fig:all_dh_prototype"
data-reference-type="ref"
data-reference="fig:all_dh_prototype">[fig:all_dh_prototype]</a>i), and
hatched color for categorical hunches (Figure <a
href="#fig:all_dh_prototype" data-reference-type="ref"
data-reference="fig:all_dh_prototype">[fig:all_dh_prototype]</a>a), in
both cases using the same encoding channel as the original data.
However, some hunches cannot be expressed using the same visual
encoding. For example, a range value hunch (providing an estimate that a
value should be in a certain range) is not compatible with a bar chart
encoding used for the original data. To address this, we use a position
encoding on the same scale as the bars, showing the middle and the
extend of the range (Figure <a href="#fig:all_dh_prototype"
data-reference-type="ref"
data-reference="fig:all_dh_prototype">[fig:all_dh_prototype]</a>e). We
use similar techniques for directional value hunches (Figure <a
href="#fig:all_dh_prototype" data-reference-type="ref"
data-reference="fig:all_dh_prototype">[fig:all_dh_prototype]</a>b) and
hunches that do not fit on the scale of a chart (Figure <a
href="#fig:all_dh_prototype" data-reference-type="ref"
data-reference="fig:all_dh_prototype">[fig:all_dh_prototype]</a>h).</p>
<p>To reconcile this guideline with the guideline of making hunches
distinct from visualizations of the original data, in our demo we relied
on using an additional visual channel that was not used in the original
visualization: sketchy texture.</p>
<h4 id="keep-data-hunches-close."><strong>Keep data hunches
close.</strong></h4>
<p>As assessment data hunches (comments, ratings, etc.) are not
expressed in data space, using the same visual encoding is not feasible.
However, designers should ensure that assessment hunches can still be
read easily together with the original data. For example, instead of
showing assessment hunches in a table, they could be rendered next to
the element they are referring to, illustrated for annotations in
Figure <a href="#fig:all_dh_prototype" data-reference-type="ref"
data-reference="fig:all_dh_prototype">[fig:all_dh_prototype]</a>d and
for ratings in Figure <a href="#fig:all_dh_prototype"
data-reference-type="ref"
data-reference="fig:all_dh_prototype">[fig:all_dh_prototype]</a>g. If a
textual hunch requires more space than is available in the chart, we
truncate the comment and reveal the full text in a tooltip. We also
considered what to do with assessment hunches referring to the whole
dataset and opted for placing a note and an asterisk next to the chart
title (Figure <a href="#fig:all_dh_prototype" data-reference-type="ref"
data-reference="fig:all_dh_prototype">[fig:all_dh_prototype]</a>k); our
reasoning is that analysts might read the title and caption as they are
attempting to understand the visualization.</p>
<p><img src="figures/input.png" alt="image" /> <span id="fig:input"
label="fig:input"></span></p>
<p><img src="figures/in_chart_input.png" alt="image" /> <span
id="fig:in_chart_input" label="fig:in_chart_input"></span></p>
<h4 id="use-direct-manipulation."><strong>Use direct
manipulation.</strong></h4>
<p>Data hunches emerge when analysts explore the data and examine the
data visualizations. Hence, the thinking and analysis process happens in
visual and data space. While we lay out different approaches for
recording data hunches in Section <a href="#sec:recording"
data-reference-type="ref" data-reference="sec:recording">4</a>, we argue
that recording of data hunches should be done as close to the way the
data and the data hunch are presented as possible. In our prototype, we
trigger recordings by right-clicking on a mark or legend whenever
possible and provide methods to record a data hunch through direct
manipulation of the data hunch as it will appear once it is recorded
(Figure <a href="#fig:input" data-reference-type="ref"
data-reference="fig:input">[fig:input]</a>). When recording a hunch in
data space, or when recording an assessment hunch, a visualization can
provide visual feedback for the analysts (Figure <a
href="#fig:in_chart_input" data-reference-type="ref"
data-reference="fig:in_chart_input">[fig:in_chart_input]</a>). Also, in
our prototype, we place the input forms for data hunches right next to
the visual elements in the chart.</p>
<h4 id="design-for-data-hunches."><strong>Design for data
hunches.</strong></h4>
<p>Not all visualization techniques are equally well suited to visualize
data hunches. In our prototype, we have chosen a bar chart with
categorical values because bar charts are an important class of
visualizations, and because they have affordances that are compatible
with data hunches. For example, an analyst could express a value data
hunch on top of an individual bar without affecting a neighboring bar.
Other visualization techniques, however, do not equally support such
similarities. For example resizing a segment in a pie chart, or in a
stacked bar chart, requires affecting the other data marks, or
overplotting.</p>
<p>Another consideration is the complexity of a chart: the more complex,
and the more visual channels are used, the more difficult it will likely
be to find a suitable design for data hunches. Similarly, visualizations
that give overviews of large amounts of data, like cluster heatmaps,
will require different approaches for data hunches, as the manipulation
of individual data items is less relevant and the visualizing of the
hunches more challenging.</p>
<p>However, even when using a visualization technique that is well
suited for data hunches, like bar charts, line charts, or scatterplots
(see Figure <a href="#fig:externalize_design_space"
data-reference-type="ref"
data-reference="fig:externalize_design_space">[fig:externalize_design_space]</a>),
there are suggestions we recommend that a visualization designer keep in
mind to better support data hunches. For example, our original design
used vertical bars (see Figure <a href="#fig:non-sketchy-design"
data-reference-type="ref"
data-reference="fig:non-sketchy-design">1</a>). However, we quickly
found that vertical bars are problematic for rendering longer comments
(assessment hunches) next to the bar due to the text orientation, so we
switched to horizontal bars. Likewise, our original design had a chart
title and a subtitle at the top, which made it difficult to find a
suitable place for comments on the whole chart. Hence, we moved the
title below the chart, and reserved space below the subtitle for
comments. Finally, we found it useful to leave white-space from the
beginning, so that data hunches can be easily expressed and rendered.
For example, our prototype has large margins to the right of the bar
chart, so that larger value hunches and comments can be effectively
rendered. The designer can also use binning and grouping to organize
several data hunches and associate them with a data point, a technique
that Badam et al. <span class="citation"
data-cites="badam_integrating_2022">(Badam, Chandrasegaran, and Elmqvist
2022)</span> adopted in FacetNotes. While these specific examples may
not directly translate to other visualization techniques, the larger
lesson of thinking about position, layout, and space for data hunches as
a designer creates a visualization, holds.</p>
<h4 id="design-for-collaboration."><strong>Design for
collaboration.</strong></h4>
<p>Data hunches are predominantly a medium to communicate knowledge
about data to others, and hence, data hunches are inherently
collaborative. Data analysis activities are also commonly collaborative
efforts in the first place. We argue that data hunches should be
designed with collaboration in mind.</p>
<p>Our prototype acknowledges the importance of collaboration by
allowing multiple people to log in and review data hunches. However, we
also speculate that enabling multiple collaborators to record only data
hunches might be insufficient, as collaborators might also want to
endorse, reject, or comment on others’ data hunches. To address this
aspect of collaborating, we introduce features to endorse or reject a
particular data hunch, using a thumbs-up or thumbs-down metaphor,
illustrated in Figure <a href="#fig:scalability"
data-reference-type="ref" data-reference="fig:scalability">2</a>.
Another more expressive method is to add capability to comment on data
hunches. This way, a team member can express their sentiment about a
data hunch without having to re-specify a data hunch they endorse.</p>
<h4 id="elicit-context-and-accountability."><strong>Elicit context and
accountability.</strong></h4>
<p><em>What</em> a data hunch says about the data is different from
<em>why</em> a person has the hunch. The context of a data hunch is as
critical for its interpretation as the context of the data. Similarly,
the reasoning and identity of the data hunch author can effect how a
data hunch is perceived and trusted.</p>
<p>We propose that along with recording data hunches, context is
important for establishing trustworthiness. This may include reasoning
about the data hunch or the identity of person making the hunch. As
designers work with stakeholders to determine how data hunches are
recorded, they should also explore how important contextual information
can be recorded and shared. In our prototype, we require that analysts
provide reasoning for and express their confidence in a data hunch when
recording it (Figure <a href="#fig:input" data-reference-type="ref"
data-reference="fig:input">[fig:input]</a>). Additionally, the identity
of the data hunch author is recorded as an attribute of the data hunch.
We then visualize these attributes in a tool-tip (Figure <a
href="#fig:all_dh_prototype" data-reference-type="ref"
data-reference="fig:all_dh_prototype">[fig:all_dh_prototype]</a>),
although other more salient approaches are conceivable. For example, it
might be worth exploring the use of opacity to encode the confidence of
a data hunch. These attributes not only enrich the recording of data
hunches, but also allow for features such as filtering and sorting.</p>
<p>We acknowledge a tension between revealing identities, to ensure
accountability and leverage networks of trust, and the desire to be
anonymous to record inconvenient opinions or facts. In prior work, for
example, we found that experts in an organization were unwilling to
record hunches under their name due to tensions in the organization. In
addition to logged-in recording of data hunches, our prototype also
provides a “log-in as guest” option to record a hunch without revealing
one’s identity. We further discuss this issue in Section <a
href="#sec:discussion" data-reference-type="ref"
data-reference="sec:discussion">9</a>.</p>
<figure>
<img src="figures/scalability.png" id="fig:scalability"
alt="Collaboration and scalability. Collaboration features, such as endorsing, rejecting, and commenting on data hunches, help in reducing the need for logging similar data hunches in the first place. Different visual encodings account for scalability in value data hunches. If more than three data hunches are logged for a single bar, we replace the sketchy bars with sketchy ticks." />
<figcaption aria-hidden="true">Collaboration and scalability.
Collaboration features, such as endorsing, rejecting, and commenting on
data hunches, help in reducing the need for logging similar data hunches
in the first place. Different visual encodings account for scalability
in value data hunches. If more than three data hunches are logged for a
single bar, we replace the sketchy bars with sketchy ticks.</figcaption>
</figure>
<p><span id="fig:scalability" label="fig:scalability"></span></p>
<div class="figure*">
<p><img src="figures/case_study_students.png" alt="image" /></p>
</div>
<h1 id="sec:prototype">Prototype Implementation</h1>
<p>Our web-based prototype (available at <a
href="https://vdl.sci.utah.edu/data-hunch/"
class="uri">https://vdl.sci.utah.edu/data-hunch/</a>) implements
visualization methods for all types of hunches we describe (see
Section <a href="#sec:data_hunches" data-reference-type="ref"
data-reference="sec:data_hunches">2</a>). For specific value hunches, we
also provide dedicated methods for larger numbers of data hunches. The
prototype also implements all appropriate methods for recording data
hunches (see Section <a href="#sec:recording" data-reference-type="ref"
data-reference="sec:recording">4</a>) for each type. A specific hunch,
for example, can be recorded in data space through form-based
manipulation, through model-based manipulation, as well as in visual
space through direct manipulation and free-form sketching.</p>
<p>A concern for designing hunches was scalability: how we can show many
different data hunches reliably on top of a visualization. We address
scalability in two ways: first, we implement dedicated encodings for
hunches in case too many hunches are recorded. Figure <a
href="#fig:scalability" data-reference-type="ref"
data-reference="fig:scalability">2</a> shows specific value hunches on
top of three bars. We use sketchy bars for one or two hunches on top of
a bar, but switch to sketchy ticks for more hunches, as shown on the
top. However, switching from bars to ticks violates the guideline for
making hunches appear similar to the original marks and hence is a
trade-off we have to make. Second, we support collaborative features. If
a data hunch is already present, another person sharing the hunch could
endorse, reject, or comment on data hunches instead of logging a new
data hunch, thereby reducing the number of hunches that need to be
visualized simultaneously.</p>
<p>We use three example datasets: COVID-19 case counts in selected
countries, greenhouse gas emissions across the food supply chain (both
downloaded from OurWorldInData), and the size of research areas at the
School of Computing at the University of Utah. Data is loaded from CSV
files, where data hunches are stored in a Firebase database. Data
hunches can be freely added by guests or after signing-in via Google. A
tabular visualization (Figure <a href="#fig:all_dh_prototype"
data-reference-type="ref"
data-reference="fig:all_dh_prototype">[fig:all_dh_prototype]</a>) gives
an overview of all data hunches and their meta-data, although all
relevant information about data hunches is also available through the
visualization interface.</p>
<p>Our prototype is open source; the code is available at <a
href="https://github.com/visdesignlab/data-hunches-package"><a
href="github.com/visdesignlab/data-hunches-package"
class="uri">github.com/visdesignlab/data-hunches-package</a></a>. We use
React and D3 for rendering the UI and the visualizations, and the
RoughJS library (<a href="https://roughjs.com"><a href="roughjs.com"
class="uri">roughjs.com</a></a>), which is based on the techniques for
sketchy rendering developed by Wood et al. <span class="citation"
data-cites="wood_sketchy_2012">(Wood et al. 2012)</span>, to render
visual elements for data hunches in sketchy patterns.</p>
<h1 id="sec:methodology">Methodology</h1>
<p>Our methodology for theorizing about data hunches and developing a
framework for recording and communicating data hunches was based on
reflective practices <span class="citation"
data-cites="fleck_reflecting_2010 schon_reflective_2017">(Fleck and
Fitzpatrick 2010; Schön 2017)</span>. We began by reflecting on our
experiences working with a variety of domain experts who have rich
knowledge about their data, knowledge that was not captured in their
datasets. Through group discussions about our experiences, we recognized
the missing formalization of personal knowledge and its impact in data
analysis. We began mapping out the scope of data hunches, the
relationship between data hunches and existing visualization concepts,
and how hunches have been reported in the existing literature. This
process included a literature search into data feminism, critical data
studies, and uncertainty, as well as searching works on design studies
and reviewing any reported sources of qualitative uncertainty in
previous design studies.</p>
<p>After investigating the landscape of data hunches, we iteratively
developed our understanding of data hunches. The iterations critically
reflected illustrative examples from our prior experiences, and design
spaces proposed for interactive visualization interfaces, uncertainty
visualization, and collaborative sense-making. We additionally received
feedback from our research lab and colleagues and made adjustments
accordingly. We used the design space to re-imagine visualization
systems presented in several design studies <span class="citation"
data-cites="heer_voyagers_2009 mccurdy_framework_2019 lin_sanguine:_2021">(Heer,
Viégas, and Wattenberg 2009; Mccurdy, Gerdes, and Meyer 2019; Lin et al.
2021)</span>.</p>
<p>Initially, we considered our framework for recording data hunches as
a medium for collecting input and knowledge about a dataset from a
general audience. Our reasoning was that the crowd might have insights
about datasets based on their own experiences, such as collective and
local knowledge about a COVID-19 dataset. We came to appreciate that a
key challenge of data hunches, however, is that they could be used to
explain away inconvenient data points, or that they could exacerbate the
problem of confirmation bias <span class="citation"
data-cites="fischer_knowledge_2019 lee_viral_2021">(Fischer 2019; Lee et
al. 2021)</span>. We thus made the decision to argue for scoping data
hunches to collaborative settings with groups of experts who are
supported by networks of trust <span class="citation"
data-cites="passi_trust_2018">(Passi and Jackson 2018)</span>. We
discuss the potential benefits and harms that could be associated when
data hunches are implemented for general audience systems in Section <a
href="#sec:discussion" data-reference-type="ref"
data-reference="sec:discussion">9</a>.</p>
<p>Finally, we used an iterative design and development process for our
prototype system, with the intent of embodying our ideas and evaluating
their feasibility. Over a period of six months, we sketched alternative
design ideas and implemented promising solutions, which we then
evaluated within our team of four authors and discussed within our
research lab. We designed and implemented many variations that we
subsequently abandoned for various reasons (see the <span
style="color: blue"><a
href="https://osf.io/syjkf/?view_only=67f3ec0c06c5427281c2b4c1288a0d2f">supplementary
material</a></span> for examples). We describe the lessons learned from
the entire process that stretched over more than a year as guidelines in
Section <a href="#sec:guidelines" data-reference-type="ref"
data-reference="sec:guidelines">5</a>.</p>
<h1 id="sec:usage_scenario">Usage Scenario</h1>
<p>Here we illustrate how data hunches could be used in a scenario with
real data about the size of research areas in the University of Utah’s
School of Computing, shown in Figure <a href="#fig:case_study_students"
data-reference-type="ref"
data-reference="fig:case_study_students">[fig:case_study_students]</a>.
To begin, a faculty member, also a co-author of this paper, first
noticed that while the largest bar was for <em>UNKNOWN</em> students,
there was another bar labeled <em>N/A</em>. He recorded a hunch that
<em>N/A</em> should be removed (a structural hunch) and that
<em>UNKNOWN</em> should be bigger (a value hunch).</p>
<p>Upon reviewing the classification of research areas into larger
fields, he expressed concern that <em>Databases</em> is classified as
<em>Data and Visualization</em>, given his knowledge about the type of
research conducted by the database groups at the University of Utah, and
that it should rather be in the <em>Computer Systems</em> category — he
recorded his hunch about the different classification of the bar (a
value hunch). He expressed a similar data hunch for <em>Graphics</em>,
which should be in the <em>Other</em> bin.</p>
<p>When reviewing the number of <em>Architecture</em> researchers, he
was surprised by the seemingly high number. He provided a value hunch
that he considered closer to reality, and added a comment speculating
that some Electrical and Computer Engineering students advised by
Computer Science faculty are included in this count. Finally, he
realized that <em>Robotics</em> is likely shown smaller than it is,
probably because some students are incorrectly classified as <em>AI</em>
instead. He left a value range hunch also noting his reasoning. This
faculty member then passed on the visualization to a second faculty
member, another co-author of this paper, who reviewed his hunches,
upvoted several, and left some additional hunches about her own thoughts
on where the data did not reflect the make-up of the department.</p>
<h1 id="sec:discussion">Discussion and Future Work</h1>
<p>Inspired by the breadth of opportunities that data hunches open up,
in this section we present a series of discussion threads and future
work possibilities. Some of these threads reflect on ethical
considerations for ensuring data hunches are used in productive and
positive ways, and others consider a number of technical and design
challenges for consideration. We end with a brief statement about the
opportunity that data hunches point to for considering new perspectives
on knowledge.</p>
<h4 id="challenges-for-designing-with-data-hunches.">Challenges for
Designing with Data Hunches.</h4>
<p>As a proof of concept, we used a bar chart to demonstrate how data
hunches can be implemented in data visualizations. As we developed the
prototype, we realized how quickly the additional layers of data hunches
can complicate the visualizations. It was challenging to add data
hunches in the chart while keeping the original visualization legible.
For data hunches to become established, we need to develop designs for a
wide range of visualization types. We believe that our guidelines apply
broadly, but the specific design decisions in our prototype might not
easily translate to certain types of space-filling visualizations, such
as pie charts, treemaps, or icicle plots. Also, while our framework
allows for structural hunches through inclusion and exclusion, tabular
data is a simple case compared to network data, which has much more
complex structural (topological) information. Hence, we believe that a
good amount of design work remains to be done to make data hunches work
well with such datasets.</p>
<h4 id="potential-for-harm.">Potential for Harm.</h4>
<p>In our advocacy for data hunches, we focus only on the use cases for
analysts with rich knowledge about their field. Narrowing the target
audience ensures that the data hunches are based on analysts’ knowledge
and experience of the field, and can provide a richer view of the
phenomenon that the data represents. The limitation can also avoid
misuse and misinformation in data hunches. In an ideal world, our
definition of data hunches implicitly assumes that all users are
positively contributing to the visualizations when expressing their
opinions and knowledge of the data. However, even with good intentions,
there is a risk that data hunches could be used to explain away
inconvenient data points, or to reinforce an analyst’s preconceived
ideas. Because of such risk, it is critical that data hunches are
treated fundamentally different from data, even if they are recorded in
the same space. A design for data hunches should go to great lengths to
avoid any confusion between the data and the data hunch. Such risk also
makes it important that data hunches come with explanations and
justifications. Using these techniques, analysts can evaluate a data
hunch holistically and judge whether it is reasonable.</p>
<p>Much remains to be explored when considering how to support the
public with the ability of recording data hunches on visualizations.
Data hunches can encourage open conversations about data and
visualizations, similar to current online Q&amp;A forums. Previous
research concluded that identity-based trust, social feedback, and
exposure all have positive effects on knowledge contribution <span
class="citation" data-cites="guan_knowledge_2018">(Guan et al.
2018)</span>. Visualizations supporting data hunches are similar to
online forums, where users can communicate their knowledge or opinions
about the data through a set of techniques and receive feedback (such as
upvotes, downvotes, and comments) from other users in the community, and
the association with identity, feedback, and exposure can positively
promote conversation and knowledge sharing about the data. However, what
if a hunch is wrong? Or worse, what if a hunch is maliciously intended
as misinformation? Previous research has discovered that data can be
used in contradicting ways, depending on how people understand the
phenomenon <span class="citation" data-cites="lee_viral_2021">(Lee et
al. 2021)</span>. It is possible that a system that supports recording
and visualization of data hunches can be used with malicious intent to
fulfill a personal agenda. Moderators, allowing voting, and providing
reports mechanism can potentially help with the issue, but it remains an
open question that requires further investigations.</p>
<h4 id="trust-and-privacy">Trust and Privacy</h4>
<p>While we suggest that identities behind data hunches can play a big
role in building trust for data hunches, privacy can become an issue and
concern for analysts. In some settings, the politics of an organization
or field could cause vulnerable people to remain silent about
contradictory hunches, depriving others of important perspectives <span
class="citation" data-cites="mohammed_understanding_2001">(Mohammed
2001)</span>. Anonymity, however, can be equally caustic by invoking
negative behavior toward others with opposite views <span
class="citation" data-cites="barlett_anonymously_2015">(Barlett
2015)</span>. How to ensure the value, credibility, trustworthiness, and
transparency of data hunches is an important, yet open, question.</p>
<p>Another interesting, open question is what happens to someone’s trust
in a visualization and the underlying data when data hunches are
communicated in a tool. Previous work <span class="citation"
data-cites="kim_data_2018">(Kim, Reinecke, and Hullman 2018)</span> has
reported that <em>social information</em> can affect a user’s trust and
memorability about the data visualization. We anticipate similar effects
with the inclusion of data hunches. We argue in this paper that data is
an imperfect representation of reality, and making that imperfection
visible is one goal of our work. However, if data hunches make people
less trusting, will designers avoid including them, as they sometimes do
with uncertainty <span class="citation"
data-cites="hullman_why_2020">(Jessica Hullman 2020)</span>?</p>
<p>A reader may trust the visualization more when data hunches are
provided by experts, or when data hunches are highly rated. On the other
hand, if too many data hunches disagree with the original data, the
reader may trust the source of the visualization less. In the end, the
goal of conceptualizing data hunches and proposing a design space for
them is to formally recognize the role of personal knowledge in
understanding data and empower users to express their views. Designers
should fully consider the possible impacts of data hunches before
committing to including or excluding them. The work we present in this
paper is only the first step in exploring a rich space about how, why,
and when to include personal knowledge about data in visualizations.</p>
<h4 id="application-scenarios">Application Scenarios</h4>
<p>Another important consideration is what types of visualization
systems and scenarios are most appropriate for implementing mechanisms
that support data hunches. We believe that most visual data analysis
involves hunches, but designing and developing tools that support
externalization and communication of multiple data hunches is likely to
require significant effort. We see two possible application scenarios
that we think justify this effort. On the one hand, data hunches could
be integrated in widely used off-the-shelf visualization libraries. For
example, adding the capability to visualize and record data hunches to a
library such as Altair <span class="citation"
data-cites="vanderplas_altair:_2018">(VanderPlas et al. 2018)</span>, an
interactive visualization library for Python and Jupyter notebooks,
could make data hunches accessible to a wide range of audiences. A
second possible application is bespoke systems that support recording
and communicating data hunches to be implemented primarily in scenarios
where the topic of the data is of shared interest among larger
communities of experts. For example, a recent project elicited feedback
from the scientific community on an animation of the SARS-CoV-2 protein
structure <span class="citation"
data-cites="iwasa_sars-cov-2_2020">(Iwasa et al. 2020)</span>. Unlike
visualization tools designed for an individual research lab, such
applications target a wider audience with shared interests, where
visualizing data hunches can lead to deeper impact compared to casual
visualizations. Finally, as designs for data hunches become more common
and libraries to add data hunches to visualization become available, it
might be feasible to integrate recording and visualization of data
hunches into a wider set of visualization tools.</p>
<h4 id="data-hunches-as-structured-data">Data Hunches as Structured
Data</h4>
<p>Depending on the type of hunch and the method for recording it, data
hunches can also become structured data. Value hunches recorded via data
space or direct manipulation, for example, are either directly available
in the same space as the original data, or can be easily translated back
into data space. They are, hence, different from e.g., annotations
provided on top of a figure, as they can be reused whenever a dataset is
reused. For example, if a data hunch is recorded for a visualization of
a dataset in a Jupyter notebook, the data hunch could be shown not only
in that one visualization, but could also be propagated to all
subsequent and prior visualizations that are based on that dataset,
thereby surfacing the hunch at all stages of the analysis process. Data
hunches could also be preserved as datasets are updated, as long as the
structure is preserved. For example, if a dataset is refined over time,
possibly because of discrepancies recorded as data hunches, a new
version of a dataset could be overlaid with data hunches recorded for
the old version of the dataset, to see whether the hunches expressed
still apply. Overlaying data hunches could be combined with an explicit
comparison of datasets <span class="citation"
data-cites="gadhave_reusing_2022">(Gadhave, Cutler, and Lex
2022)</span>. However, such a workflow would incur additional visual
complexity and hence would require dedicated methods to manage that
complexity.</p>
<h4 id="epistemology">Epistemology</h4>
<p>The visualization community has characterized the imperfect and
partiality of data as uncertainty; however, this is not the only
available classification. Within the fields of critical data studies and
digital humanities, data is an artifact of decisions and situated
contexts that reflect one captured slice of reality: “<em>Data are
capta</em>, taken not given, constructed as an interpretation of the
phenomenal world, not inherent in it” <span class="citation"
data-cites="drucker_humanities_2011">(Drucker 2011)</span>. Data, then,
as an object of decision-making practices, is one representation of many
possibilities. This recognition is important because it highlights the
non-neutrality of data <span class="citation"
data-cites="dignazio_feminist_2016 correll_ethical_2019 dork_critical_2013">(D’Ignazio
and Klein 2016; Correll 2019; Dörk et al. 2013)</span>. These
perspective stem from different epistemological roots. Feminist
perspectives on data are based on the theory of <em>situated
knowledges</em> <span class="citation"
data-cites="haraway_situated_1988">(Haraway 1988)</span>. This theory
posits that knowledge cannot be obtained from a single source, but
rather is best derived through a collection and collaboration across
partial and overlapping perspectives. Data, similarly, cannot fully
represent the natural world. From this theoretical grounding, data and
data hunches would capture different perspectives of reality but
contribute to a richer more complete picture. This is only a musing,
however, leading us to bigger questions such as: In what ways could
other epistemologies be productive in visualization research? Could we
better characterize and describe the entangled relationship between
data, visualizations, and people?</p>
<h1 id="conclusion">Conclusion</h1>
<p>In this work, we framed the personal knowledge about how
representative data is, defining such knowledge as data hunches, and
analyzed the implication of supporting data hunches in data analysis. We
proposed techniques for recording and communicating data hunches in data
visualizations, listed design guidelines, and implemented a prototype to
demonstrate data hunches in action. The ultimate goal of this work is to
formalize and recognize the significant role that personal knowledge has
in understanding data, which many works overlook, and elevate this
personal knowledge into another form of information that can be
explicitly recorded and utilized. Through this work, we seek to question
the notion of data being the gold standard of representing phenomena in
the world, and open up the potential to grow visualization research
beyond constrained notions of data.</p>
<div id="refs" class="references csl-bib-body hanging-indent"
role="doc-bibliography">
<div id="ref-aisch_you_2015" class="csl-entry" role="doc-biblioentry">
Aisch, Gregor, Amanda Cox, and Kevin Quealy. 2015. <span>“You <span>Draw
It</span>: <span>How Family Income Predicts Children</span>’s
<span>College Chances</span>.”</span> <em>The New York Times</em>, May.
</div>
<div id="ref-arnold_factsheets:_2019" class="csl-entry"
role="doc-biblioentry">
Arnold, M., R. K. E. Bellamy, M. Hind, S. Houde, S. Mehta, A.
Mojsilović, R. Nair, et al. 2019. <span>“<span>FactSheets</span>:
<span>Increasing</span> Trust in <span>AI</span> Services Through
Supplier’s Declarations of Conformity.”</span> <em>IBM Journal of
Research and Development</em> 63 (4/5): 6:1–13. <a
href="https://doi.org/10.1147/JRD.2019.2942288">https://doi.org/10.1147/JRD.2019.2942288</a>.
</div>
<div id="ref-badam_integrating_2022" class="csl-entry"
role="doc-biblioentry">
Badam, Sriram Karthik, Senthil Chandrasegaran, and Niklas Elmqvist.
2022. <span>“Integrating Annotations into Multidimensional Visual
Dashboards.”</span> <em>Information Visualization</em> 21 (3): 270–84.
<a
href="https://doi.org/10.1177/14738716221079591">https://doi.org/10.1177/14738716221079591</a>.
</div>
<div id="ref-barlett_anonymously_2015" class="csl-entry"
role="doc-biblioentry">
Barlett, Christopher P. 2015. <span>“Anonymously Hurting Others Online:
<span>The</span> Effect of Anonymity on Cyberbullying Frequency.”</span>
<em>Psychology of Popular Media Culture</em> 4 (2): 70–79. <a
href="https://doi.org/10.1037/a0034335">https://doi.org/10.1037/a0034335</a>.
</div>
<div id="ref-baudel_information_2006" class="csl-entry"
role="doc-biblioentry">
Baudel, Thomas. 2006. <span>“From Information Visualization to Direct
Manipulation: Extending a Generic Visualization Framework for the
Interactive Editing of Large Datasets.”</span> In <em>Proceedings of the
19th Annual <span>ACM</span> Symposium on <span>User</span> Interface
Software and Technology</em>, 67–76. <span>UIST</span> ’06.
<span>Association for Computing Machinery</span>. <a
href="https://doi.org/10.1145/1166253.1166265">https://doi.org/10.1145/1166253.1166265</a>.
</div>
<div id="ref-bonneau_overview_2014" class="csl-entry"
role="doc-biblioentry">
Bonneau, Georges-Pierre, Hans-Christian Hege, Chris R. Johnson, Manuel
M. Oliveira, Kristin Potter, Penny Rheingans, and Thomas Schultz. 2014.
<span>“Overview and <span class="nocase">State-of-the-Art</span> of
<span>Uncertainty Visualization</span>.”</span> In <em>Scientific
<span>Visualization</span></em>, edited by Charles D. Hansen, Min Chen,
Christopher R. Johnson, Arie E. Kaufman, and Hans Hagen, 3–27.
<span>London</span>: <span>Springer</span>. <a
href="https://doi.org/10.1007/978-1-4471-6497-5_1">https://doi.org/10.1007/978-1-4471-6497-5_1</a>.
</div>
<div id="ref-boukhelifa_evaluating_2012" class="csl-entry"
role="doc-biblioentry">
Boukhelifa, Nadia, Anastasia Bezerianos, Tobias Isenberg, and
Jean-Daniel Fekete. 2012. <span>“Evaluating <span>Sketchiness</span> as
a <span>Visual Variable</span> for the <span>Depiction</span> of
<span>Qualitative Uncertainty</span>.”</span> <em>IEEE Transactions on
Visualization and Computer Graphics</em> 18 (12): 2769–78. <a
href="https://doi.org/10.1109/TVCG.2012.220.">https://doi.org/10.1109/TVCG.2012.220.</a>
</div>
<div id="ref-boukhelifa_how_2017" class="csl-entry"
role="doc-biblioentry">
Boukhelifa, Nadia, Marc-Emmanuel Perrin, Samuel Huron, and James Eagan.
2017. <span>“How <span>Data Workers Cope</span> with
<span>Uncertainty</span>: <span>A Task Characterisation
Study</span>.”</span> In <em>Proceedings of the 2017 <span>CHI
Conference</span> on <span>Human Factors</span> in <span>Computing
Systems</span></em>, 3645–56. <span>CHI</span> ’17. <span>Association
for Computing Machinery</span>. <a
href="https://doi.org/10.1145/3025453.3025738">https://doi.org/10.1145/3025453.3025738</a>.
</div>
<div id="ref-brodlie_review_2012" class="csl-entry"
role="doc-biblioentry">
Brodlie, Ken, Rodolfo Allendes Osorio, and Adriano Lopes. 2012. <span>“A
<span>Review</span> of <span>Uncertainty</span> in <span>Data
Visualization</span>.”</span> In <em>Expanding the
<span>Frontiers</span> of <span>Visual Analytics</span> and
<span>Visualization</span></em>, edited by John Dill, Rae Earnshaw,
David Kasik, John Vince, and Pak Chung Wong, 81–109.
<span>London</span>: <span>Springer London</span>. <a
href="https://doi.org/10.1007/978-1-4471-2804-5_6">https://doi.org/10.1007/978-1-4471-2804-5_6</a>.
</div>
<div id="ref-brynjolfsson_rapid_2016" class="csl-entry"
role="doc-biblioentry">
Brynjolfsson, Erik, and Kristina McElheran. 2016. <span>“The <span>Rapid
Adoption</span> of <span>Data-Driven Decision-Making</span>.”</span>
<em>American Economic Review</em> 106 (5): 133–39. <a
href="https://doi.org/10.1257/aer.p20161016">https://doi.org/10.1257/aer.p20161016</a>.
</div>
<div id="ref-correll_ethical_2019" class="csl-entry"
role="doc-biblioentry">
Correll, Michael. 2019. <span>“Ethical <span>Dimensions</span> of
<span>Visualization Research</span>.”</span> In <em>Proceedings of the
2019 <span>CHI Conference</span> on <span>Human Factors</span> in
<span>Computing Systems</span></em>, 188:1–13. <span>CHI</span> ’19.
<span>Association for Computing Machinery</span>. <a
href="https://doi.org/10.1145/3290605.3300418">https://doi.org/10.1145/3290605.3300418</a>.
</div>
<div id="ref-correll_error_2014" class="csl-entry"
role="doc-biblioentry">
Correll, Michael, and Michael Gleicher. 2014. <span>“Error <span>Bars
Considered Harmful</span>: <span>Exploring Alternate Encodings</span>
for <span>Mean</span> and <span>Error</span>.”</span> <em>IEEE Trans.
Visual. Comput. Graphics</em> 20 (12): 2142–51. <a
href="https://doi.org/10.1109/TVCG.2014.2346298">https://doi.org/10.1109/TVCG.2014.2346298</a>.
</div>
<div id="ref-correll_value-suppressing_2018" class="csl-entry"
role="doc-biblioentry">
Correll, Michael, Dominik Moritz, and Jeffrey Heer. 2018.
<span>“Value-<span>Suppressing Uncertainty Palettes</span>.”</span> In
<em>Proceedings of the 2018 <span>CHI Conference</span> on <span>Human
Factors</span> in <span>Computing Systems</span></em>, 642:1–11.
<span>CHI</span> ’18. <span>Association for Computing Machinery</span>.
<a
href="https://doi.org/10.1145/3173574.3174216">https://doi.org/10.1145/3173574.3174216</a>.
</div>
<div id="ref-covitt_untangling_2022" class="csl-entry"
role="doc-biblioentry">
Covitt, Beth A., and Charles W. Anderson. 2022. <span>“Untangling
<span>Trustworthiness</span> and <span>Uncertainty</span> in
<span>Science</span>.”</span> <em>Sci &amp; Educ</em>, February. <a
href="https://doi.org/10.1007/s11191-022-00322-6">https://doi.org/10.1007/s11191-022-00322-6</a>.
</div>
<div id="ref-cutler_trrack:_2020" class="csl-entry"
role="doc-biblioentry">
Cutler, Zachary T, Kiran Gadhave, and Alexander Lex. 2020.
<span>“Trrack: <span>A Library</span> for <span>Provenance
Tracking</span> in <span>Web-Based Visualizations</span>.”</span> In
<em><span>IEEE Visualization Conference</span> (<span>VIS</span>)</em>,
116–20. <span>IEEE</span>. <a
href="https://doi.org/10.1109/VIS47514.2020.00030">https://doi.org/10.1109/VIS47514.2020.00030</a>.
</div>
<div id="ref-dignazio_feminist_2016" class="csl-entry"
role="doc-biblioentry">
D’Ignazio, Catherine, and Lauren F Klein. 2016. <span>“Feminist
<span>Data Visualization</span>.”</span> In <em>Workshop on
<span>Visualization</span> for the <span>Digital Humanities</span>
(<span>VIS4DH</span>)</em>.
</div>
<div id="ref-dork_critical_2013" class="csl-entry"
role="doc-biblioentry">
Dörk, Marian, Patrick Feng, Christopher Collins, and Sheelagh
Carpendale. 2013. <span>“Critical <span>InfoVis</span>: Exploring the
Politics of Visualization.”</span> In <em><span>CHI</span> ’13
<span>Extended Abstracts</span> on <span>Human Factors</span> in
<span>Computing Systems</span></em>, 2189–98. <span>CHI EA</span>’13.
<span>Association for Computing Machinery</span>. <a
href="https://doi.org/10.1145/2468356.2468739">https://doi.org/10.1145/2468356.2468739</a>.
</div>
<div id="ref-drucker_humanities_2011" class="csl-entry"
role="doc-biblioentry">
Drucker, Johanna. 2011. <span>“Humanities <span>Approaches</span> to
<span>Graphical Display</span>.”</span> <em>Digital Humanities
Quarterly</em> 5 (1).
</div>
<div id="ref-feng_hindsight:_2017" class="csl-entry"
role="doc-biblioentry">
Feng, Mi, Cheng Deng, Evan M. Peck, and Lane Harrison. 2017.
<span>“<span>HindSight</span>: <span>Encouraging Exploration</span>
Through <span>Direct Encoding</span> of <span>Personal Interaction
History</span>.”</span> <em>IEEE Transactions on Visualization and
Computer Graphics</em> 23 (1): 351–60. <a
href="https://doi.org/10.1109/TVCG.2016.2599058">https://doi.org/10.1109/TVCG.2016.2599058</a>.
</div>
<div id="ref-fischer_knowledge_2019" class="csl-entry"
role="doc-biblioentry">
Fischer, Frank. 2019. <span>“Knowledge Politics and Post-Truth in
Climate Denial: On the Social Construction of Alternative Facts.”</span>
<em>Critical Policy Studies</em> 13 (2): 133–52. <a
href="https://doi.org/10.1080/19460171.2019.1602067">https://doi.org/10.1080/19460171.2019.1602067</a>.
</div>
<div id="ref-fleck_reflecting_2010" class="csl-entry"
role="doc-biblioentry">
Fleck, Rowanne, and Geraldine Fitzpatrick. 2010. <span>“Reflecting on
Reflection: Framing a Design Landscape.”</span> In <em>Proceedings of
the 22nd <span>Conference</span> of the <span>Computer-Human Interaction
Special Interest Group</span> of <span>Australia</span> on
<span>Computer-Human Interaction</span></em>, 216–23. <span>OZCHI</span>
’10. <span>Association for Computing Machinery</span>. <a
href="https://doi.org/10.1145/1952222.1952269">https://doi.org/10.1145/1952222.1952269</a>.
</div>
<div id="ref-nationalsciencefoundation_nsf&#39;s" class="csl-entry"
role="doc-biblioentry">
Foundation, National Science. n.d. <span>“<span>NSF</span>’s 10
<span>Big Ideas</span> - <span>Special Report</span>.”</span>
https://www.nsf.gov/news/special_reports/big_ideas/harnessing.jsp.
</div>
<div id="ref-franke_confidence_2019" class="csl-entry"
role="doc-biblioentry">
Franke, Max, Ralph Barczok, Steffen Koch, and Dorothea Weltecke. 2019.
<span>“Confidence as <span class="nocase">First-class Attribute</span>
in <span>Digital Humanities Data</span>.”</span> In <em>Proceedings of
the 4th <span>VIS4DH Workshop</span></em>.
</div>
<div id="ref-gadhave_reusing_2022" class="csl-entry"
role="doc-biblioentry">
Gadhave, Kiran, Zach Tyler Cutler, and Alexander Lex. 2022.
<span>“Reusing <span>Interactive Analysis Workflows</span>.”</span>
<em>EuroVis (to Appear)</em>, <span>EUROVIS</span> ’22,. <a
href="https://doi.org/10.31219/osf.io/udqjr">https://doi.org/10.31219/osf.io/udqjr</a>.
</div>
<div id="ref-gadhave_predicting_2021" class="csl-entry"
role="doc-biblioentry">
Gadhave, Kiran, Jochen Görtler, Zach Cutler, Carolina Nobre, Oliver
Deussen, Miriah Meyer, Jeff M. Phillips, and Alexander Lex. 2021.
<span>“Predicting Intent Behind Selections in Scatterplot
Visualizations.”</span> <em>Information Visualization</em> 20 (4):
207–28. <a
href="https://doi.org/10.1177/14738716211038604">https://doi.org/10.1177/14738716211038604</a>.
</div>
<div id="ref-gebru_datasheets_2021" class="csl-entry"
role="doc-biblioentry">
Gebru, Timnit, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman
Vaughan, Hanna Wallach, Hal Daumé Iii, and Kate Crawford. 2021.
<span>“Datasheets for <span>Datasets</span>.”</span> <em>Communications
of the ACM</em> 64 (12): 86–92. <a
href="https://doi.org/10.1145/3458723">https://doi.org/10.1145/3458723</a>.
</div>
<div id="ref-goyal_effects_2013" class="csl-entry"
role="doc-biblioentry">
Goyal, Nitesh, Gilly Leshed, and Susan R. Fussell. 2013. <span>“Effects
of <span>Visualization</span> and <span
class="nocase">Note-taking</span> on <span>Sensemaking</span> and
<span>Analysis</span>.”</span> In <em>Proceedings of the <span>SIGCHI
Conference</span> on <span>Human Factors</span> in <span>Computing
Systems</span></em>, 2721–24. <span>CHI</span> ’13. <span>Association
for Computing Machinery</span>. <a
href="https://doi.org/10.1145/2470654.2481376">https://doi.org/10.1145/2470654.2481376</a>.
</div>
<div id="ref-guan_knowledge_2018" class="csl-entry"
role="doc-biblioentry">
Guan, Tao, Le Wang, Jiahua Jin, and Xiaolong Song. 2018.
<span>“Knowledge Contribution Behavior in Online
<span>Q</span>&amp;<span>A</span> Communities: <span>An</span> Empirical
Investigation.”</span> <em>Computers in Human Behavior</em> 81: 137–47.
<a
href="https://doi.org/10.1016/j.chb.2017.12.023">https://doi.org/10.1016/j.chb.2017.12.023</a>.
</div>
<div id="ref-haraway_situated_1988" class="csl-entry"
role="doc-biblioentry">
Haraway, Donna. 1988. <span>“Situated <span>Knowledges</span>: <span>The
Science Question</span> in <span>Feminism</span> and the
<span>Privilege</span> of <span>Partial Perspective</span>.”</span>
<em>Feminist Studies</em> 14 (3): 575. <a
href="https://doi.org/10.2307/3178066">https://doi.org/10.2307/3178066</a>.
</div>
<div id="ref-heer_voyagers_2009" class="csl-entry"
role="doc-biblioentry">
Heer, Jeffrey, Fernanda B Viégas, and Martin Wattenberg. 2009.
<span>“Voyagers and Voyeurs: <span>Supporting</span> Asynchronous
Collaborative Visualization.”</span> <em>Commun. ACM</em> 52 (1): 87–97.
<a
href="https://doi.org/10.1145/1435417.1435439">https://doi.org/10.1145/1435417.1435439</a>.
</div>
<div id="ref-hegarty_individual_1997" class="csl-entry"
role="doc-biblioentry">
Hegarty, Mary, and Kathryn Steinhoff. 1997. <span>“Individual
Differences in Use of Diagrams as External Memory in Mechanical
Reasoning.”</span> <em>Learning and Individual Differences</em> 9 (1):
19–42. <a
href="https://doi.org/10.1016/S1041-6080(97)90018-2">https://doi.org/10.1016/S1041-6080(97)90018-2</a>.
</div>
<div id="ref-hullman_why_2020" class="csl-entry" role="doc-biblioentry">
Hullman, Jessica. 2020. <span>“Why <span>Authors Don</span>’t
<span>Visualize Uncertainty</span>.”</span> <em>IEEE Trans. Visual.
Comput. Graphics</em> 26 (1): 130–39. <a
href="https://doi.org/10.1109/TVCG.2019.2934287">https://doi.org/10.1109/TVCG.2019.2934287</a>.
</div>
<div id="ref-hullman_hypothetical_2015" class="csl-entry"
role="doc-biblioentry">
Hullman, Jessica, Paul Resnick, and Eytan Adar. 2015.
<span>“Hypothetical <span>Outcome Plots Outperform Error Bars</span> and
<span>Violin Plots</span> for <span>Inferences</span> about
<span>Reliability</span> of <span>Variable Ordering</span>.”</span>
<em>PLOS ONE</em> 10 (11): 1–25. <a
href="https://doi.org/10.1371/journal.pone.0142444">https://doi.org/10.1371/journal.pone.0142444</a>.
</div>
<div id="ref-hullman_pursuit_2019" class="csl-entry"
role="doc-biblioentry">
Hullman, J., X. Qiao, M. Correll, A. Kale, and M. Kay. 2019. <span>“In
<span>Pursuit</span> of <span>Error</span>: <span>A Survey</span> of
<span>Uncertainty Visualization Evaluation</span>.”</span> <em>IEEE
Transactions on Visualization and Computer Graphics</em> 25 (1): 903–13.
<a
href="https://doi.org/10.1109/TVCG.2018.2864889">https://doi.org/10.1109/TVCG.2018.2864889</a>.
</div>
<div id="ref-isenberg_collaborative_2011" class="csl-entry"
role="doc-biblioentry">
Isenberg, Petra, Niklas Elmqvist, Jean Scholtz, Daniel Cernea, Kwan-Liu
Ma, and Hans Hagen. 2011. <span>“Collaborative Visualization:
<span>Definition</span>, Challenges, and Research Agenda.”</span>
<em>Information Visualization</em> 10 (4): 310–26. <a
href="https://doi.org/10.1177/1473871611412817">https://doi.org/10.1177/1473871611412817</a>.
</div>
<div id="ref-iwasa_sars-cov-2_2020" class="csl-entry"
role="doc-biblioentry">
Iwasa, Janet, Miriah Meyer, Alexander Lex, Jen Rogers, Ann (Hui) Liu,
and Margot Riggi. 2020. <span>“<span>SARS-CoV-2 Visualization</span> and
<span>Annotation Project</span>.”</span> <em>The Animation Lab</em>.
https://animationlab.utah.edu/cova.
</div>
<div id="ref-johnson_next_2003" class="csl-entry"
role="doc-biblioentry">
Johnson, C. R., and A. R. Sanderson. 2003. <span>“A <span>Next
Step</span>: <span>Visualizing Errors</span> and
<span>Uncertainty</span>.”</span> <em>IEEE Computer Graphics and
Applications</em> 23 (5): 6–10. <a
href="https://doi.org/10.1109/MCG.2003.1231171">https://doi.org/10.1109/MCG.2003.1231171</a>.
</div>
<div id="ref-karer_insight_2021" class="csl-entry"
role="doc-biblioentry">
Karer, B., H. Hagen, and D. J. Lehmann. 2021. <span>“Insight
<span>Beyond Numbers</span>: <span>The Impact</span> of
<span>Qualitative Factors</span> on <span>Visual Data
Analysis</span>.”</span> <em>IEEE Transactions on Visualization and
Computer Graphics</em> 27 (2): 1011–21. <a
href="https://doi.org/ghxc23">https://doi.org/ghxc23</a>.
</div>
<div id="ref-kim_inking_2019" class="csl-entry" role="doc-biblioentry">
Kim, Yea-Seul, Nathalie Henry Riche, Bongshin Lee, Matthew Brehmer,
Michel Pahud, Ken Hinckley, and Jessica Hullman. 2019. <span>“Inking
<span>Your Insights</span>: <span>Investigating Digital Externalization
Behaviors During Data Analysis</span>.”</span> In <em>Proceedings of the
2019 <span>ACM International Conference</span> on <span>Interactive
Surfaces</span> and <span>Spaces</span></em>, 255–67. <span>ISS</span>
’19. <span>Association for Computing Machinery</span>. <a
href="https://doi.org/10.1145/3343055.3359714">https://doi.org/10.1145/3343055.3359714</a>.
</div>
<div id="ref-kim_explaining_2017" class="csl-entry"
role="doc-biblioentry">
Kim, Yea-Seul, Katharina Reinecke, and Jessica Hullman. 2017.
<span>“Explaining the <span>Gap</span>: <span>Visualizing One</span>’s
<span>Predictions Improves Recall</span> and <span>Comprehension</span>
of <span>Data</span>.”</span> In <em>Proceedings of the 2017 <span>CHI
Conference</span> on <span>Human Factors</span> in <span>Computing
Systems</span></em>, 1375–86. <span>CHI</span> ’17. <span>Association
for Computing Machinery</span>. <a
href="https://doi.org/10.1145/3025453.3025592">https://doi.org/10.1145/3025453.3025592</a>.
</div>
<div id="ref-kim_data_2018" class="csl-entry" role="doc-biblioentry">
———. 2018. <span>“Data <span>Through Others</span>’ <span>Eyes</span>:
<span>The Impact</span> of <span>Visualizing Others</span>’
<span>Expectations</span> on <span>Visualization
Interpretation</span>.”</span> <em>IEEE Trans. Visual. Comput.
Graphics</em> 24 (1): 760–69. <a
href="https://doi.org/10.1109/TVCG.2017.2745240">https://doi.org/10.1109/TVCG.2017.2745240</a>.
</div>
<div id="ref-lee_viral_2021" class="csl-entry" role="doc-biblioentry">
Lee, Crystal, Tanya Yang, Gabrielle D Inchoco, Graham M. Jones, and
Arvind Satyanarayan. 2021. <span>“Viral <span>Visualizations</span>:
<span>How Coronavirus Skeptics Use Orthodox Data Practices</span> to
<span>Promote Unorthodox Science Online</span>.”</span> In
<em>Proceedings of the 2021 <span>CHI Conference</span> on <span>Human
Factors</span> in <span>Computing Systems</span></em>, 607:1–18.
<span>CHI</span> ’21. <span>Association for Computing Machinery</span>.
</div>
<div id="ref-lin_sanguine:_2021" class="csl-entry"
role="doc-biblioentry">
Lin, Haihan, Ryan A Metcalf, Jack Wilburn, and Alexander Lex. 2021.
<span>“Sanguine: <span>Visual</span> Analysis for Patient Blood
Management.”</span> <em>Information Visualization</em> 20 (2-3): 123–37.
<a
href="https://doi.org/10.1177/14738716211028565">https://doi.org/10.1177/14738716211028565</a>.
</div>
<div id="ref-mahyar_note-taking_2012" class="csl-entry"
role="doc-biblioentry">
Mahyar, Narges, Ali Sarvghad, and Melanie Tory. 2012. <span>“Note-Taking
in Co-Located Collaborative Visual Analytics: <span>Analysis</span> of
an Observational Study.”</span> <em>Information Visualization</em> 11
(3): 190–204. <a
href="https://doi.org/10.1177/1473871611433713">https://doi.org/10.1177/1473871611433713</a>.
</div>
<div id="ref-marasoiu_clarifying_2016" class="csl-entry"
role="doc-biblioentry">
Marasoiu, Mariana, Alan F. Blackwell, Advait Sarkar, and Martin Spott.
2016. <span>“Clarifying <span>Hypotheses</span> by <span>Sketching
Data</span>.”</span> In <em>Proceedings of the <span>Eurographics</span>
/ <span>IEEE VGTC Conference</span> on <span>Visualization</span>:
<span>Short Papers</span></em>, 125–29. <span>EuroVis</span> ’16.
<span>Eurographics Association</span>. <a
href="https://doi.org/10.5555/3058878.3058905">https://doi.org/10.5555/3058878.3058905</a>.
</div>
<div id="ref-mathisen_insideinsights:_2019" class="csl-entry"
role="doc-biblioentry">
Mathisen, A., T. Horak, C. N. Klokmose, K. Grønbæk, and N. Elmqvist.
2019. <span>“<span>InsideInsights</span>: <span>Integrating Data-Driven
Reporting</span> in <span>Collaborative Visual Analytics</span>.”</span>
<em>Computer Graphics Forum</em> 38 (3): 649–61. <a
href="https://doi.org/10.1111/cgf.13717">https://doi.org/10.1111/cgf.13717</a>.
</div>
<div id="ref-mccurdy_framework_2019" class="csl-entry"
role="doc-biblioentry">
Mccurdy, Nina, Julie Gerdes, and Miriah Meyer. 2019. <span>“A
<span>Framework</span> for <span>Externalizing Implicit Error Using
Visualization</span>.”</span> <em>IEEE Transactions on Visualization and
Computer Graphics</em> 25 (1): 925–35. <a
href="https://doi.org/10.1109/TVCG.2018.2864913">https://doi.org/10.1109/TVCG.2018.2864913</a>.
</div>
<div id="ref-mohammed_understanding_2001" class="csl-entry"
role="doc-biblioentry">
Mohammed, Susan. 2001. <span>“Toward an <span>Understanding</span> of
<span>Cognitive Consensus</span> in a <span>Group Decision-Making
Context</span>.”</span> <em>The Journal of Applied Behavioral
Science</em> 37 (4): 408–25. <a
href="https://doi.org/10.1177/0021886301374002">https://doi.org/10.1177/0021886301374002</a>.
</div>
<div id="ref-morgan_use_2014" class="csl-entry" role="doc-biblioentry">
Morgan, M. Granger. 2014. <span>“Use (and Abuse) of Expert Elicitation
in Support of Decision Making for Public Policy.”</span> <em>Proceedings
of the National Academy of Sciences</em> 111 (20): 7176–84. <a
href="https://doi.org/10.1073/pnas.1319946111">https://doi.org/10.1073/pnas.1319946111</a>.
</div>
<div id="ref-muller_how_2019" class="csl-entry" role="doc-biblioentry">
Muller, Michael, Ingrid Lange, Dakuo Wang, David Piorkowski, Jason Tsay,
Q. Vera Liao, Casey Dugan, and Thomas Erickson. 2019. <span>“How
<span>Data Science Workers Work</span> with <span>Data</span>:
<span>Discovery</span>, <span>Capture</span>, <span>Curation</span>,
<span>Design</span>, <span>Creation</span>.”</span> In <em>Proceedings
of the 2019 <span>CHI Conference</span> on <span>Human Factors</span> in
<span>Computing Systems</span></em>, 126:1–15. <span>CHI</span> ’19.
<span>Association for Computing Machinery</span>. <a
href="https://doi.org/10.1145/3290605.3300356">https://doi.org/10.1145/3290605.3300356</a>.
</div>
<div id="ref-nowak_designing_2020" class="csl-entry"
role="doc-biblioentry">
Nowak, Stan, Lyn Bartram, and Pascal Haegeli. 2020. <span>“Designing for
<span>Ambiguity</span>: <span>Visual Analytics</span> in <span>Avalanche
Forecasting</span>.”</span> In <em>2020 <span>IEEE Visualization
Conference</span> (<span>VIS</span>)</em>, 81–85. <span>IEEE</span>. <a
href="https://doi.org/10.1109/VIS47514.2020.00023">https://doi.org/10.1109/VIS47514.2020.00023</a>.
</div>
<div id="ref-padilla_powerful_2020" class="csl-entry"
role="doc-biblioentry">
Padilla, Lace M K, Sarah H Creem-Regehr, and William Thompson. 2020.
<span>“The Powerful Influence of Marks: <span>Visual</span> and
Knowledge-Driven Processing in Hurricane Track Displays.”</span>
<em>Journal of Experimental Psychology: Applied</em> 26 (1): 1–15. <a
href="https://doi.org/10.1037/xap0000245">https://doi.org/10.1037/xap0000245</a>.
</div>
<div id="ref-padilla_uncertain_2021" class="csl-entry"
role="doc-biblioentry">
Padilla, Lace M. K., Maia Powell, Matthew Kay, and Jessica Hullman.
2021. <span>“Uncertain <span>About Uncertainty</span>: <span>How
Qualitative Expressions</span> of <span>Forecaster Confidence Impact
Decision-Making With Uncertainty Visualizations</span>.”</span>
<em>Front. Psychol.</em> 11 (January): 579267. <a
href="https://doi.org/10.3389/fpsyg.2020.579267">https://doi.org/10.3389/fpsyg.2020.579267</a>.
</div>
<div id="ref-panagiotidou_implicit_2021" class="csl-entry"
role="doc-biblioentry">
Panagiotidou, Georgia, Ralf Vandam, Jeroen Poblome, and Andrew Vande
Moere. 2021. <span>“Implicit <span>Error</span>,
<span>Uncertainty</span> and <span>Confidence</span> in
<span>Visualization</span>: An <span>Archaeological Case
Study</span>.”</span> <em>IEEE Transactions on Visualization and
Computer Graphics</em>, no. 1 (June): 1–1. <a
href="https://doi.org/10.1109/TVCG.2021.3088339">https://doi.org/10.1109/TVCG.2021.3088339</a>.
</div>
<div id="ref-passi_trust_2018" class="csl-entry" role="doc-biblioentry">
Passi, Samir, and Steven J. Jackson. 2018. <span>“Trust in <span>Data
Science</span>: <span>Collaboration</span>, <span>Translation</span>,
and <span>Accountability</span> in <span>Corporate Data Science
Projects</span>.”</span> <em>Proceedings of the ACM on Human-Computer
Interaction</em> 2 (CSCW): 136:1–28. <a
href="https://doi.org/10.1145/3274405">https://doi.org/10.1145/3274405</a>.
</div>
<div id="ref-potter_visualizing_2010" class="csl-entry"
role="doc-biblioentry">
Potter, K., J. Kniss, R. Riesenfeld, and C. R. Johnson. 2010.
<span>“Visualizing <span>Summary Statistics</span> and
<span>Uncertainty</span>.”</span> <em>Computer Graphics Forum</em> 29
(3): 823–32. <a
href="https://doi.org/10.1111/j.1467-8659.2009.01677.x">https://doi.org/10.1111/j.1467-8659.2009.01677.x</a>.
</div>
<div id="ref-potter_interactive_2012" class="csl-entry"
role="doc-biblioentry">
Potter, Kristin, Robert M. Kirby, Dongbin Xiu, and Chris R. Johnson.
2012. <span>“<span>INTERACTIVE VISUALIZATION OF PROBABILITY AND
CUMULATIVE DENSITY FUNCTIONS</span>.”</span> <em>Int J Uncertain
Quantif</em> 2 (4): 397–412. <a
href="https://doi.org/10.1615/Int.J.UncertaintyQuantification.2012004074">https://doi.org/10.1615/Int.J.UncertaintyQuantification.2012004074</a>.
</div>
<div id="ref-potter_quantification_2012" class="csl-entry"
role="doc-biblioentry">
Potter, Kristin, Paul Rosen, and Chris R. Johnson. 2012. <span>“From
<span>Quantification</span> to <span>Visualization</span>: <span>A
Taxonomy</span> of <span>Uncertainty Visualization
Approaches</span>.”</span> In <em>Uncertainty
<span>Quantification</span> in <span>Scientific Computing</span></em>,
226–49. <span>London</span>: <span>Springer</span>. <a
href="https://doi.org/10.1007/978-3-642-32677-6_15">https://doi.org/10.1007/978-3-642-32677-6_15</a>.
</div>
<div id="ref-quispel_would_2014" class="csl-entry"
role="doc-biblioentry">
Quispel, Annemarie, and Alfons Maes. 2014. <span>“Would You Prefer Pie
or Cupcakes? <span>Preferences</span> for Data Visualization Designs of
Professionals and Laypeople in Graphic Design.”</span> <em>Journal of
Visual Languages &amp; Computing</em> 25 (2): 107–16. <a
href="https://doi.org/10.1016/j.jvlc.2013.11.007">https://doi.org/10.1016/j.jvlc.2013.11.007</a>.
</div>
<div id="ref-romat_activeink:_2019" class="csl-entry"
role="doc-biblioentry">
Romat, Hugo, Nathalie Henry Riche, Ken Hinckley, Bongshin Lee, Caroline
Appert, Emmanuel Pietriga, and Christopher Collins. 2019.
<span>“<span>ActiveInk</span>: (<span>Th</span>)<span>Inking</span> with
<span>Data</span>.”</span> In <em>Proceedings of the 2019 <span>CHI
Conference</span> on <span>Human Factors</span> in <span>Computing
Systems</span></em>, 42:1–13. <span>CHI</span> ’19. <span>Association
for Computing Machinery</span>. <a
href="https://doi.org/10.1145/3290605.3300272">https://doi.org/10.1145/3290605.3300272</a>.
</div>
<div id="ref-saket_visualization_2017" class="csl-entry"
role="doc-biblioentry">
Saket, Bahador, Hannah Kim, Eli T. Brown, and Alex Endert. 2017.
<span>“Visualization by <span>Demonstration</span>: <span>An Interaction
Paradigm</span> for <span>Visual Data Exploration</span>.”</span>
<em>IEEE Transactions on Visualization and Computer Graphics</em> 23
(1): 331–40. <a
href="https://doi.org/10.1109/TVCG.2016.2598839">https://doi.org/10.1109/TVCG.2016.2598839</a>.
</div>
<div id="ref-schon_reflective_2017" class="csl-entry"
role="doc-biblioentry">
Schön, Donald A. 2017. <em>The <span>Reflective Practitioner</span>:
<span>How Professionals Think</span> in <span>Action</span></em>.
<span>Oxfordshire, England</span>: <span>Routledge</span>.
</div>
<div id="ref-thomson_typology_2005" class="csl-entry"
role="doc-biblioentry">
Thomson, Judi, Elizabeth Hetzler, Alan MacEachren, Mark Gahegan, and
Misha Pavel. 2005. <span>“A Typology for Visualizing
Uncertainty.”</span> In <em>Visualization and <span>Data Analysis</span>
2005</em>, 5669:146–57. <span>SPIE</span>. <a
href="https://doi.org/10.1117/12.587254">https://doi.org/10.1117/12.587254</a>.
</div>
<div id="ref-troilo_perception_2016" class="csl-entry"
role="doc-biblioentry">
Troilo, Michael, Adrien Bouchet, Timothy L. Urban, and William A.
Sutton. 2016. <span>“Perception, Reality, and the Adoption of Business
Analytics: <span>Evidence</span> from <span>North American</span>
Professional Sport Organizations.”</span> <em>Omega</em>, Business
<span>Analytics</span>, 59 (March): 72–83. <a
href="https://doi.org/10.1016/j.omega.2015.05.011">https://doi.org/10.1016/j.omega.2015.05.011</a>.
</div>
<div id="ref-vanderbles_communicating_2019" class="csl-entry"
role="doc-biblioentry">
van der Bles, Anne Marthe, Sander van der Linden, Alexandra L. J.
Freeman, James Mitchell, Ana B. Galvao, Lisa Zaval, and David J.
Spiegelhalter. 2019. <span>“Communicating Uncertainty about Facts,
Numbers and Science.”</span> <em>R. Soc. Open Sci.</em> 6 (5): 181870.
<a
href="https://doi.org/10.1098/rsos.181870">https://doi.org/10.1098/rsos.181870</a>.
</div>
<div id="ref-vanderplas_altair:_2018" class="csl-entry"
role="doc-biblioentry">
VanderPlas, Jacob, Brian E Granger, Jeffrey Heer, Dominik Moritz, Kanit
Wongsuphasawat, Arvind Satyanarayan, Eitan Lees, Ilia Timofeev, Ben
Welsh, and Scott Sievert. 2018. <span>“Altair: Interactive Statistical
Visualizations for <span>Python</span>.”</span> <em>Journal of Open
Source Software</em> 3 (32): 1057.
</div>
<div id="ref-viegas_manyeyes:_2007" class="csl-entry"
role="doc-biblioentry">
Viegas, Fernanda B., Martin Wattenberg, Frank van Ham, Jesse Kriss, and
Matt McKeon. 2007. <span>“<span>ManyEyes</span>: A <span>Site</span> for
<span>Visualization</span> at <span>Internet Scale</span>.”</span>
<em>IEEE Transactions on Visualization and Computer Graphics</em> 13
(6): 1121–28. <a
href="https://doi.org/10.1109/TVCG.2007.70577">https://doi.org/10.1109/TVCG.2007.70577</a>.
</div>
<div id="ref-walker_defining_2003" class="csl-entry"
role="doc-biblioentry">
Walker, W. E., P. Harremoës, J. Rotmans, J. P. van der Sluijs, M. B. A.
van Asselt, P. Janssen, and M. P. Krayer von Krauss. 2003.
<span>“Defining <span>Uncertainty</span>: <span>A Conceptual
Basis</span> for <span>Uncertainty Management</span> in
<span>Model-Based Decision Support</span>.”</span> <em>Integrated
Assessment</em> 4 (1): 5–17. <a
href="https://doi.org/10.1076/iaij.4.1.5.16466">https://doi.org/10.1076/iaij.4.1.5.16466</a>.
</div>
<div id="ref-walny_active_2018" class="csl-entry"
role="doc-biblioentry">
Walny, Jagoda, Samuel Huron, Charles Perin, Tiffany Wun, Richard Pusch,
and Sheelagh Carpendale. 2018. <span>“Active <span>Reading</span> of
<span>Visualizations</span>.”</span> <em>IEEE Transactions on
Visualization and Computer Graphics</em> 24 (1): 770–80. <a
href="https://doi.org/10.1109/TVCG.2017.2745958">https://doi.org/10.1109/TVCG.2017.2745958</a>.
</div>
<div id="ref-walny_visual_2011" class="csl-entry"
role="doc-biblioentry">
Walny, J., S. Carpendale, N. Henry Riche, G. Venolia, and P. Fawcett.
2011. <span>“Visual <span>Thinking In Action</span>:
<span>Visualizations As Used On Whiteboards</span>.”</span> <em>IEEE
Transactions on Visualization and Computer Graphics</em> 17 (12):
2508–17. <a
href="https://doi.org/10.1109/TVCG.2011.251">https://doi.org/10.1109/TVCG.2011.251</a>.
</div>
<div id="ref-wang_how_2019" class="csl-entry" role="doc-biblioentry">
Wang, April Yi, Anant Mittal, Christopher Brooks, and Steve Oney. 2019.
<span>“How <span>Data Scientists Use Computational Notebooks</span> for
<span>Real-Time Collaboration</span>.”</span> <em>Proc. ACM Hum.-Comput.
Interact.</em> 3 (CSCW): 39:1–30. <a
href="https://doi.org/10.1145/3359141">https://doi.org/10.1145/3359141</a>.
</div>
<div id="ref-willett_understanding_2015" class="csl-entry"
role="doc-biblioentry">
Willett, Wesley, Pascal Goffin, and Petra Isenberg. 2015.
<span>“Understanding <span>Digital Note-Taking Practice</span> for
<span>Visualization</span>.”</span> <em>IEEE Computer Graphics and
Applications</em> 35 (4): 38–51. <a
href="https://doi.org/10.1109/MCG.2015.52">https://doi.org/10.1109/MCG.2015.52</a>.
</div>
<div id="ref-wittenbrink_glyphs_1996" class="csl-entry"
role="doc-biblioentry">
Wittenbrink, C. M, A. T Pang, and S. K Lodha. 1996. <span>“Glyphs for
Visualizing Uncertainty in Vector Fields.”</span> <em>IEEE Transactions
on Visualization and Computer Graphics</em> 2 (3): 266–79. <a
href="https://doi.org/10.1109/2945.537309">https://doi.org/10.1109/2945.537309</a>.
</div>
<div id="ref-wood_sketchy_2012" class="csl-entry"
role="doc-biblioentry">
Wood, Jo, Petra Isenberg, Tobias Isenberg, Jason Dykes, Nadia
Boukhelifa, and Aidan Slingsby. 2012. <span>“Sketchy
<span>Rendering</span> for <span>Information
Visualization</span>.”</span> <em>IEEE Transactions on Visualization and
Computer Graphics</em> 18 (12): 2749–58. <a
href="https://doi.org/10.1109/TVCG.2012.262">https://doi.org/10.1109/TVCG.2012.262</a>.
</div>
</div>
</body>
</html>
